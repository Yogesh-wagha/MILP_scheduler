{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gzip\n",
    "# import shutil\n",
    "# from astropy.io import fits\n",
    "\n",
    "# # Input and output file paths\n",
    "# input_gz_file = '/u/ywagh/gwemopt_tests/006.gz'\n",
    "# output_fits_file = '/u/ywagh/gwemopt_tests/006.fits'\n",
    "\n",
    "# # Decompress the .gz file\n",
    "# with gzip.open(input_gz_file, 'rb') as f_in:\n",
    "#     with open(output_fits_file, 'wb') as f_out:\n",
    "#         shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "# # Open the FITS file to ensure it's correctly decompressed\n",
    "# with fits.open(output_fits_file) as hdul:\n",
    "#     print(hdul.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/ywagh/.local/lib/python3.10/site-packages/ligo/lw/lsctables.py:89: UserWarning: Wswiglal-redir-stdio:\n",
      "\n",
      "SWIGLAL standard output/error redirection is enabled in IPython.\n",
      "This may lead to performance penalties. To disable locally, use:\n",
      "\n",
      "with lal.no_swig_redirect_standard_output_error():\n",
      "    ...\n",
      "\n",
      "To disable globally, use:\n",
      "\n",
      "lal.swig_redirect_standard_output_error(False)\n",
      "\n",
      "Note however that this will likely lead to error messages from\n",
      "LAL functions being either misdirected or lost when called from\n",
      "Jupyter notebooks.\n",
      "\n",
      "To suppress this warning, use:\n",
      "\n",
      "import warnings\n",
      "warnings.filterwarnings(\"ignore\", \"Wswiglal-redir-stdio\")\n",
      "import lal\n",
      "\n",
      "  import lal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "006.gz\n",
      "event time: 2024-05-14 08:03:21.048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/ywagh/.local/lib/python3.10/site-packages/astropy/units/quantity.py:671: RuntimeWarning: invalid value encountered in divide\n",
      "  result = super().__array_ufunc__(function, method, *arrays, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2269946308b4410699907249b339ffed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/351 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.0  number of exposures could be taken tonight\n",
      "problem setup completed\n"
     ]
    }
   ],
   "source": [
    "import astroplan\n",
    "import regions\n",
    "from astropy.coordinates import ICRS, SkyCoord, AltAz, get_moon, EarthLocation, get_body\n",
    "from astropy import units as u\n",
    "from astropy.utils.data import download_file\n",
    "from astropy.table import Table, QTable, join\n",
    "from astropy.time import Time, TimeDelta\n",
    "from astropy_healpix import *\n",
    "from ligo.skymap import plot\n",
    "from ligo.skymap.io import read_sky_map\n",
    "import healpy as hp\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import datetime as dt\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from docplex.mp.model import Model\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", \"Wswiglal-redir-stdio\")\n",
    "warnings.simplefilter('ignore', astroplan.TargetNeverUpWarning)\n",
    "warnings.simplefilter('ignore', astroplan.TargetAlwaysUpWarning)\n",
    "\n",
    "# directory_path = \"/u/ywagh/test_skymaps/S240422ed.fits\"\n",
    "# skymap, metadata = read_sky_map(os.path.join(directory_path))\n",
    "\n",
    "directory_path = \"/u/ywagh/test_skymaps/\"\n",
    "filelist = sorted([f for f in os.listdir(directory_path) if f.endswith('.gz')])\n",
    "\n",
    "slew_speed = 2.5 * u.deg / u.s\n",
    "slew_accel = 0.4 * u.deg / u.s**2\n",
    "readout = 8.2 * u.s\n",
    "\n",
    "ns_nchips = 4\n",
    "ew_nchips = 4\n",
    "ns_npix = 6144\n",
    "ew_npix = 6160\n",
    "plate_scale = 1.01 * u.arcsec\n",
    "ns_chip_gap = 0.205 * u.deg\n",
    "ew_chip_gap = 0.140 * u.deg\n",
    "\n",
    "ns_total = ns_nchips * ns_npix * plate_scale + (ns_nchips - 1) * ns_chip_gap\n",
    "ew_total = ew_nchips * ew_npix * plate_scale + (ew_nchips - 1) * ew_chip_gap\n",
    "\n",
    "rcid = np.arange(64)\n",
    "\n",
    "chipid, rc_in_chip_id = np.divmod(rcid, 4)\n",
    "ns_chip_index, ew_chip_index = np.divmod(chipid, ew_nchips)\n",
    "ns_rc_in_chip_index = np.where(rc_in_chip_id <= 1, 1, 0)\n",
    "ew_rc_in_chip_index = np.where((rc_in_chip_id == 0) | (rc_in_chip_id == 3), 0, 1)\n",
    "\n",
    "ew_offsets = ew_chip_gap * (ew_chip_index - (ew_nchips - 1) / 2) + ew_npix * plate_scale * (ew_chip_index - ew_nchips / 2) + 0.5 * ew_rc_in_chip_index * plate_scale * ew_npix\n",
    "ns_offsets = ns_chip_gap * (ns_chip_index - (ns_nchips - 1) / 2) + ns_npix * plate_scale * (ns_chip_index - ns_nchips / 2) + 0.5 * ns_rc_in_chip_index * plate_scale * ns_npix\n",
    "\n",
    "ew_ccd_corners = 0.5 * plate_scale * np.asarray([ew_npix, 0, 0, ew_npix])\n",
    "ns_ccd_corners = 0.5 * plate_scale * np.asarray([ns_npix, ns_npix, 0, 0])\n",
    "\n",
    "ew_vertices = ew_offsets[:, np.newaxis] + ew_ccd_corners[np.newaxis, :]\n",
    "ns_vertices = ns_offsets[:, np.newaxis] + ns_ccd_corners[np.newaxis, :]\n",
    "\n",
    "def get_footprint(center):\n",
    "    return SkyCoord(\n",
    "        ew_vertices, ns_vertices,\n",
    "        frame=center[..., np.newaxis, np.newaxis].skyoffset_frame()\n",
    "    ).icrs\n",
    "\n",
    "url = 'https://github.com/ZwickyTransientFacility/ztf_information/raw/master/field_grid/ZTF_Fields.txt'\n",
    "filename = download_file(url)\n",
    "field_grid = QTable(np.recfromtxt(filename, comments='%', usecols=range(3), names=['field_id', 'ra', 'dec']))\n",
    "field_grid['coord'] = SkyCoord(field_grid.columns.pop('ra') * u.deg, field_grid.columns.pop('dec') * u.deg)\n",
    "field_grid = field_grid[0:881]\n",
    "\n",
    "#******************************************************************************\n",
    "skymap, metadata = read_sky_map(os.path.join(directory_path, filelist[5]))\n",
    "\n",
    "plot_filename = os.path.basename(filelist[5])\n",
    "print(plot_filename)\n",
    "# plot_filename = 'S240422ed'\n",
    "# ci\n",
    "#******************************************************************************\n",
    "\n",
    "event_time = Time(metadata['gps_time'], format='gps').utc\n",
    "gps_time = Time(metadata['gps_time'], format='gps')\n",
    "\n",
    "event_time.format = 'iso'\n",
    "print('event time:',event_time)\n",
    "observer = astroplan.Observer.at_site('Palomar')\n",
    "night_horizon = -18 * u.deg\n",
    "if observer.is_night(event_time, horizon=night_horizon):\n",
    "    start_time = event_time\n",
    "else:\n",
    "    start_time = observer.sun_set_time(\n",
    "        event_time, horizon=night_horizon, which='next')\n",
    "\n",
    "# Find the latest possible end time of observations: the time of sunrise.\n",
    "end_time = observer.sun_rise_time(\n",
    "    start_time, horizon=night_horizon, which='next')\n",
    "\n",
    "min_airmass = 2.5 * u.dimensionless_unscaled\n",
    "airmass_horizon = (90 * u.deg - np.arccos(1 / min_airmass))\n",
    "targets = field_grid['coord']\n",
    "\n",
    "# Find the time that each field rises and sets above an airmass of 2.5.\n",
    "target_start_time = Time(np.where(\n",
    "    observer.target_is_up(start_time, targets, horizon=airmass_horizon),\n",
    "    start_time,\n",
    "    observer.target_rise_time(start_time, targets, which='next', horizon=airmass_horizon)))\n",
    "target_start_time.format = 'iso'\n",
    "\n",
    "# Find the time that each field sets below the airmass limit. If the target\n",
    "# is always up (i.e., it's circumpolar) or if it sets after surnsise,\n",
    "# then set the end time to sunrise.\n",
    "target_end_time = observer.target_set_time(\n",
    "    target_start_time, targets, which='next', horizon=airmass_horizon)\n",
    "target_end_time[\n",
    "    (target_end_time.mask & ~target_start_time.mask) | (target_end_time > end_time)\n",
    "] = end_time\n",
    "target_end_time.format = 'iso'\n",
    "# Select fields that are observable for long enough for at least one exposure\n",
    "##############################################################################\n",
    "exposure_time = 180 * u.second\n",
    "exposure_time_day = exposure_time.to_value(u.day)\n",
    "\n",
    "num_visits = 3\n",
    "num_filters = 1\n",
    "\n",
    "cadence = 30         #minutes\n",
    "cadence_days = cadence / (60 * 24)\n",
    "##############################################################################\n",
    "field_grid['start_time'] = target_start_time\n",
    "field_grid['end_time'] = target_end_time\n",
    "observable_fields = field_grid[target_end_time - target_start_time >= exposure_time]\n",
    "\n",
    "# print(observable_fields)\n",
    "hpx = HEALPix(nside=256, frame=ICRS())\n",
    "\n",
    "footprint = np.moveaxis(\n",
    "    get_footprint(SkyCoord(0 * u.deg, 0 * u.deg)).cartesian.xyz.value, 0, -1)\n",
    "footprint_healpix = np.unique(np.concatenate(\n",
    "    [hp.query_polygon(hpx.nside, v, nest=(hpx.order == 'nested')) for v in footprint]))\n",
    "\n",
    "'''\n",
    "# computing the footprints of every ZTF field as HEALPix indices. Downsampling skymap to same resolution.\n",
    "'''\n",
    "footprints = np.moveaxis(get_footprint(observable_fields['coord']).cartesian.xyz.value, 0, -1)\n",
    "footprints_healpix = [\n",
    "    np.unique(np.concatenate([hp.query_polygon(hpx.nside, v) for v in footprint]))\n",
    "    for footprint in tqdm(footprints)]\n",
    "\n",
    "prob = hp.ud_grade(skymap, hpx.nside, power=-2)\n",
    "\n",
    "# k = max number of 300s exposures \n",
    "min_start = min(observable_fields['start_time'])\n",
    "max_end =max(observable_fields['end_time'])\n",
    "# min_start.format = 'jd'\n",
    "# max_end.format = 'jd'\n",
    "\n",
    "# k=30\n",
    "\n",
    "k = int(np.floor((max_end - min_start)/(exposure_time.to(u.day))))\n",
    "k = np.floor(k/(num_visits*num_filters))\n",
    "print(k,\" number of exposures could be taken tonight\")\n",
    "\n",
    "print(\"problem setup completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(start_time.isot)\n",
    "# print(end_time.iso)\n",
    "# print(end_time-start_time)\n",
    "# start = start_time.mjd\n",
    "# f = (end_time-start_time).value\n",
    "# f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number fo fields observed should be less than 20.0\n",
      "Version identifier: 22.1.1.0 | 2022-11-28 | 9160aff4d\n",
      "CPXPARAM_Read_DataCheck                          1\n",
      "Found incumbent of value 0.000000 after 0.03 sec. (24.20 ticks)\n",
      "Tried aggregator 2 times.\n",
      "MIP Presolve eliminated 784344 rows and 514583 columns.\n",
      "Aggregator did 351 substitutions.\n",
      "Reduced MIP has 1738 rows, 2088 columns, and 6504 nonzeros.\n",
      "Reduced MIP has 2088 binaries, 0 generals, 0 SOSs, and 0 indicators.\n",
      "Presolve time = 0.69 sec. (593.80 ticks)\n",
      "Probing time = 0.00 sec. (0.44 ticks)\n",
      "Tried aggregator 1 time.\n",
      "Detecting symmetries...\n",
      "Reduced MIP has 1738 rows, 2088 columns, and 6504 nonzeros.\n",
      "Reduced MIP has 2088 binaries, 0 generals, 0 SOSs, and 0 indicators.\n",
      "Presolve time = 0.01 sec. (4.02 ticks)\n",
      "Probing time = 0.00 sec. (0.44 ticks)\n",
      "MIP emphasis: balance optimality and feasibility.\n",
      "MIP search method: dynamic search.\n",
      "Parallel mode: deterministic, using up to 32 threads.\n",
      "Root relaxation solution time = 0.01 sec. (5.49 ticks)\n",
      "\n",
      "        Nodes                                         Cuts/\n",
      "   Node  Left     Objective  IInf  Best Integer    Best Bound    ItCnt     Gap\n",
      "\n",
      "*     0+    0                            0.0000        0.4087              --- \n",
      "      0     0        0.0680   102        0.0000        0.0680     1646     --- \n",
      "*     0+    0                            0.0219        0.0680           210.96%\n",
      "*     0+    0                            0.0659        0.0680             3.26%\n",
      "*     0+    0                            0.0676        0.0680             0.57%\n",
      "      0     0        0.0678   110        0.0676      Cuts: 32     1682    0.22%\n",
      "      0     0        0.0676    63        0.0676      Cuts: 30     1712    0.02%\n",
      "\n",
      "Zero-half cuts applied:  37\n",
      "Lift and project cuts applied:  1\n",
      "Gomory fractional cuts applied:  5\n",
      "\n",
      "Root node processing (before b&c):\n",
      "  Real time             =    1.98 sec. (863.30 ticks)\n",
      "Parallel b&c, 32 threads:\n",
      "  Real time             =    0.00 sec. (0.00 ticks)\n",
      "  Sync time (average)   =    0.00 sec.\n",
      "  Wait time (average)   =    0.00 sec.\n",
      "                          ------------\n",
      "Total (root+branch&cut) =    1.98 sec. (863.30 ticks)\n",
      "optimization completed\n",
      "Total probability covered: 0.06763257992776725\n",
      "20 fields selected\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f0ab8528feb43bdacdffb96e7d6fc18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worked for 20 fields\n"
     ]
    }
   ],
   "source": [
    "m1 = Model('max coverage problem')\n",
    "\n",
    "field_vars = m1.binary_var_list(len(footprints), name='field')\n",
    "pixel_vars = m1.binary_var_list(hpx.npix, name='pixel')\n",
    "\n",
    "footprints_healpix_inverse = [[] for _ in range(hpx.npix)]\n",
    "\n",
    "for field, pixels in enumerate(footprints_healpix):\n",
    "    for pixel in pixels:\n",
    "        footprints_healpix_inverse[pixel].append(field)\n",
    "\n",
    "for i_pixel, i_fields in enumerate(footprints_healpix_inverse):\n",
    "     m1.add_constraint(m1.sum(field_vars[i] for i in i_fields) >= pixel_vars[i_pixel])\n",
    "\n",
    "m1.add_constraint(m1.sum(field_vars) <= k)\n",
    "m1.maximize(m1.dot(pixel_vars, prob))\n",
    "print(f\"number fo fields observed should be less than {k}\")\n",
    "\n",
    "solution = m1.solve(log_output=True)\n",
    "\n",
    "print(\"optimization completed\")\n",
    "total_prob_covered = solution.objective_value\n",
    "\n",
    "print(\"Total probability covered:\",total_prob_covered)\n",
    "\n",
    "selected_fields_ID = [i for i, v in enumerate(field_vars) if v.solution_value == 1]\n",
    "print(len(selected_fields_ID), \"fields selected\")\n",
    "selected_fields = observable_fields[selected_fields_ID]\n",
    "# print(selected_fields)\n",
    "\n",
    "separation_matrix = selected_fields['coord'][:,np.newaxis].separation(selected_fields['coord'][np.newaxis,:])\n",
    "\n",
    "def slew_time(separation):\n",
    "   return np.where(separation <= (slew_speed**2 / slew_accel),\n",
    "                   np.sqrt(2 * separation / slew_accel),\n",
    "                   (2 * slew_speed / slew_accel) + (separation - slew_speed**2 / slew_accel) / slew_speed)\n",
    "\n",
    "slew_times = slew_time(separation_matrix).value\n",
    "\n",
    "slew_time_value = slew_times*u.second\n",
    "slew_time_day = slew_time_value.to_value(u.day)\n",
    "\n",
    "footprints_selected = np.moveaxis(get_footprint(selected_fields['coord']).cartesian.xyz.value, 0, -1)\n",
    "footprints_healpix_selected = [\n",
    "    np.unique(np.concatenate([hp.query_polygon(hpx.nside, v) for v in footprint]))\n",
    "    for footprint in tqdm(footprints_selected)]\n",
    "\n",
    "probabilities = []\n",
    "\n",
    "for field_index in range(len(footprints_healpix_selected)):\n",
    "    probability_field = np.sum(prob[footprints_healpix_selected[field_index]])\n",
    "    probabilities.append(probability_field)\n",
    "print(\"worked for\",len(probabilities),\"fields\")\n",
    "\n",
    "selected_fields['probabilities'] = probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docplex.mp.model import Model\n",
    "import numpy as np\n",
    "from astropy import units as u\n",
    "from astropy.time import Time, TimeDelta\n",
    "\n",
    "def create_scheduling_model(observable_fields, slew_times, num_visits=3, cadence_minutes=30,\n",
    "                          exposure_time=180*u.second, prob_weight=0.9):\n",
    "    \"\"\"\n",
    "    Creates and solves a MILP model for scheduling field observations.\n",
    "    Times are normalized relative to the earliest start time.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    observable_fields : astropy.table.Table\n",
    "        Table containing field information including IDs, coordinates, start/end times\n",
    "    slew_times : numpy.ndarray\n",
    "        Matrix of slew times between fields\n",
    "    num_visits : int\n",
    "        Maximum number of visits per field\n",
    "    cadence_minutes : int\n",
    "        Minimum time between revisits in minutes\n",
    "    exposure_time : astropy.units.Quantity\n",
    "        Duration of each exposure\n",
    "    prob_weight : float\n",
    "        Weight given to probability maximization (vs time minimization)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert other time quantities to days\n",
    "    exposure_time_days = exposure_time.to(u.day).value\n",
    "    cadence_days = cadence_minutes / (24 * 60)\n",
    "    \n",
    "    # Create model\n",
    "    m = Model('field_scheduling')\n",
    "    \n",
    "    num_fields = len(selected_fields)\n",
    "    cad_list = np.ones(num_fields)*cadence_days\n",
    "    # Define variables\n",
    "    # Binary variable x[i,v]: 1 if field i is observed for visit v\n",
    "    x = m.binary_var_matrix(num_fields, num_visits, name='field_observation')\n",
    "    \n",
    "    # Continuous variable t[i,v]: start time of observation for field i, visit v (in days from reference)\n",
    "    # t = m.continuous_var_matrix(num_fields, num_visits, lb=0,ub = reference_time, name='start_time')\n",
    "    \n",
    "    tc = [[m.continuous_var(\n",
    "    lb=(row['start_time'] - start_time).to_value(u.day),\n",
    "    ub=(row['end_time'] - start_time - exposure_time).to_value(u.day),\n",
    "    name=f\"start_time_field_{i}_visit_{v}\")\n",
    "    for v in range(num_visits*num_filters)] \n",
    "    for i, row in enumerate(selected_fields)]\n",
    "    \n",
    "    # Constraints\n",
    "    for i in range(num_fields):\n",
    "        field_start = tc[i]\n",
    "        field_end = field_start+cad_list\n",
    "        \n",
    "        for v in range(num_visits):\n",
    "            # Time window constraints\n",
    "            m.add_constraint(tc[i,v] >= field_start * x[i,v])\n",
    "            m.add_constraint(tc[i,v] <= field_end * x[i,v] + (1 - x[i,v]) * field_end)\n",
    "            \n",
    "            # Ensure visits happen in order\n",
    "            if v > 0:\n",
    "                m.add_constraint(tc[i,v] >= tc[i,v-1] + cadence_days * x[i,v])\n",
    "                # If a visit v is scheduled, all previous visits must be scheduled\n",
    "                m.add_constraint(x[i,v] <= x[i,v-1])\n",
    "    \n",
    "    # Non-overlap constraints between all fields\n",
    "    for i in range(num_fields):\n",
    "        for j in range(i+1, num_fields):\n",
    "            for v1 in range(num_visits):\n",
    "                for v2 in range(num_visits):\n",
    "                    slew_days = slew_times[i,j] / (24 * 3600)  # Convert to days\n",
    "                    m.add_indicator_constraint(\n",
    "                        x[i,v1],\n",
    "                        tc[j,v2] >= tc[i,v1] + exposure_time_days + slew_days - \n",
    "                        (1 - x[j,v2]) * max(normalized_end_times)\n",
    "                    )\n",
    "                    m.add_indicator_constraint(\n",
    "                        x[j,v2],\n",
    "                        tc[i,v1] >= tc[j,v2] + exposure_time_days + slew_days - \n",
    "                        (1 - x[i,v1]) * max(normalized_end_times)\n",
    "                    )\n",
    "    \n",
    "    # Objective function\n",
    "    total_prob = m.sum(x[i,v] * selected_fields['probabilities'][i] \n",
    "                      for i in range(num_fields) \n",
    "                      for v in range(num_visits))\n",
    "    \n",
    "    total_time = m.sum(t[i,v] for i in range(num_fields) for v in range(num_visits))\n",
    "    \n",
    "    # Maximize probability while minimizing total time\n",
    "    m.maximize(prob_weight * total_prob - (1 - prob_weight) * total_time)\n",
    "    \n",
    "    # Solve the model\n",
    "    solution = m.solve(log_output=True)\n",
    "    \n",
    "    if solution is None:\n",
    "        raise ValueError(\"No feasible solution found\")\n",
    "    \n",
    "    # Extract results\n",
    "    field_matrix = np.zeros((num_fields, num_visits))\n",
    "    time_matrix = np.zeros((num_fields, 2 * num_visits))  # Start and end times for each visit\n",
    "    \n",
    "    for i in range(num_fields):\n",
    "        for v in range(num_visits):\n",
    "            field_matrix[i,v] = x[i,v].solution_value\n",
    "            if x[i,v].solution_value > 0.5:  # Account for floating point errors\n",
    "                time_matrix[i,2*v] = tc[i,v].solution_value  # Start time (days from reference)\n",
    "                time_matrix[i,2*v+1] = tc[i,v].solution_value + exposure_time_days  # End time\n",
    "    \n",
    "    return field_matrix, time_matrix, solution.objective_value, reference_time\n",
    "\n",
    "# Helper function to convert normalized times to readable format if needed\n",
    "def format_time_matrix(time_matrix, reference_time):\n",
    "    \"\"\"\n",
    "    Convert normalized days to readable times\n",
    "    \"\"\"\n",
    "    formatted_times = []\n",
    "    for row in time_matrix:\n",
    "        row_times = []\n",
    "        for tc in row:\n",
    "            if tc > 0:  # Only convert non-zero times\n",
    "                absolute_time = Time(reference_time + tc, format='jd')\n",
    "                row_times.append(absolute_time.iso)\n",
    "            else:\n",
    "                row_times.append('')\n",
    "        formatted_times.append(row_times)\n",
    "    return formatted_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (3,) (20,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m field_matrix, time_matrix, objective_value \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_scheduling_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mselected_fields\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mslew_time_day\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_visits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcadence_minutes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Convert times to readable format\u001b[39;00m\n\u001b[1;32m      9\u001b[0m formatted_times \u001b[38;5;241m=\u001b[39m format_time_matrix(time_matrix, event_time)\n",
      "Cell \u001b[0;32mIn[16], line 54\u001b[0m, in \u001b[0;36mcreate_scheduling_model\u001b[0;34m(observable_fields, slew_times, num_visits, cadence_minutes, exposure_time, prob_weight)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_fields):\n\u001b[1;32m     53\u001b[0m     field_start \u001b[38;5;241m=\u001b[39m tc[i]\n\u001b[0;32m---> 54\u001b[0m     field_end \u001b[38;5;241m=\u001b[39m \u001b[43mfield_start\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mcad_list\u001b[49m\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_visits):\n\u001b[1;32m     57\u001b[0m         \u001b[38;5;66;03m# Time window constraints\u001b[39;00m\n\u001b[1;32m     58\u001b[0m         m\u001b[38;5;241m.\u001b[39madd_constraint(tc[i,v] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m field_start \u001b[38;5;241m*\u001b[39m x[i,v])\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (3,) (20,) "
     ]
    }
   ],
   "source": [
    "field_matrix, time_matrix, objective_value = create_scheduling_model(\n",
    "    selected_fields,\n",
    "    slew_time_day,\n",
    "    num_visits=3,\n",
    "    cadence_minutes=30\n",
    ")\n",
    "\n",
    "# Convert times to readable format\n",
    "formatted_times = format_time_matrix(time_matrix, event_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Instead of filtering out fields, add an \"availability factor\" to each field\n",
    "# # Compute availability\n",
    "# availability = [\n",
    "#     (row['end_time'] - row['start_time']).to_value(u.day) / (end_time - start_time).to_value(u.day)\n",
    "#     for row in selected_fields\n",
    "# ]\n",
    "\n",
    "# # Add 'availability' to selected_fields\n",
    "# selected_fields['availability'] = availability\n",
    "\n",
    "# # Create selected_fil_fileds with all required columns\n",
    "# selected_fil_fileds = QTable(rows=selected_fields, names=selected_fields.colnames)\n",
    "\n",
    "# # Verify column names\n",
    "# print(\"Columns in selected_fil_fileds:\", selected_fil_fileds.colnames)\n",
    "\n",
    "# # Convert availability to a NumPy array for safe indexing\n",
    "# availabilities = np.array(selected_fil_fileds['availability'])\n",
    "\n",
    "# # Apply constraints using the availability array\n",
    "# for i in range(len(selected_fil_fileds)):\n",
    "#     min_obs = max(1, int(np.ceil(3 * availabilities[i])))\n",
    "#     m2.add_constraint(\n",
    "#         m2.sum(x[i][v] for v in range(num_visits*num_filters)) >= min_obs,\n",
    "#         ctname=f\"min_obs_field_{i}\"\n",
    "#     )\n",
    "\n",
    "\n",
    "# m2 = Model(\"Telescope Scheduling\")\n",
    "# footprints_selected = np.moveaxis(get_footprint(selected_fil_fileds['coord']).cartesian.xyz.value, 0, -1)\n",
    "# footprints_healpix_selected = [\n",
    "#     np.unique(np.concatenate([hp.query_polygon(hpx.nside, v) for v in footprint]))\n",
    "#     for footprint in tqdm(footprints_selected)]\n",
    "\n",
    "# # Compute probabilities for each field\n",
    "# probabilities = []\n",
    "# for field_index in range(len(footprints_healpix_selected)):\n",
    "#     probability_field = np.sum(prob[footprints_healpix_selected[field_index]])\n",
    "#     probabilities.append(probability_field)\n",
    "\n",
    "# # Ensure 'probability' column is properly assigned to selected_fields\n",
    "# selected_fields['probability'] = probabilities\n",
    "\n",
    "# # Create QTable with probabilities included\n",
    "# selected_fil_fileds = QTable(rows=selected_fields, names=selected_fields.colnames)\n",
    "\n",
    "# # Convert probabilities to NumPy array before using in optimization\n",
    "# probabilities = np.array(selected_fil_fileds['probability'])\n",
    "\n",
    "\n",
    "\n",
    "# # selected_fields['probabilities'] = probabilities\n",
    "# # Define observation duration and total observation window\n",
    "# delta = exposure_time.to_value(u.day)  # Observation duration per field\n",
    "# M = (selected_fil_fileds['end_time'].max() - selected_fil_fileds['start_time'].min()).to_value(u.day).item()\n",
    "\n",
    "# # Decision variables: Binary variables for each field and visit\n",
    "# x = [[m2.binary_var(name=f\"x_{i}_visit_{v}\") \n",
    "#       for v in range(num_visits*num_filters)] \n",
    "#       for i in range(len(selected_fil_fileds))]\n",
    "\n",
    "# # Continuous variables for start time of each visit\n",
    "# tc = [[m2.continuous_var(\n",
    "#     lb=(row['start_time'] - start_time).to_value(u.day),\n",
    "#     ub=(row['end_time'] - start_time - exposure_time).to_value(u.day),\n",
    "#     name=f\"start_time_field_{i}_visit_{v}\")\n",
    "#     for v in range(num_visits*num_filters)] \n",
    "#     for i, row in enumerate(selected_fil_fileds)]\n",
    "\n",
    "# # Variables for enforcing non-overlapping observations\n",
    "# visit_transition_times = [m2.continuous_var(\n",
    "#     lb=0, ub=M, name=f\"visit_transition_{v}\")\n",
    "#     for v in range(num_visits*num_filters - 1)]\n",
    "\n",
    "# # **1. Enforce Minimum Observations Proportional to Availability**\n",
    "# for i, row in enumerate(selected_fil_fileds):\n",
    "#     # min_obs = max(1, round(3 * row['availability']))  # Ensure at least 1 observation\n",
    "#     min_obs = max(1, int(np.ceil(3 * row['availability'])))  # Use ceil instead of round\n",
    "\n",
    "#     m2.add_constraint(\n",
    "#         m2.sum(x[i][v] for v in range(num_visits*num_filters)) >= min_obs,\n",
    "#         ctname=f\"min_obs_field_{i}\"\n",
    "#     )\n",
    "\n",
    "# # **2. Enforce Minimum Time Gap Between Observations (30 min)**\n",
    "# cadence_days = (30 * u.minute).to_value(u.day)  # 30 minutes in days\n",
    "\n",
    "# for i in range(len(selected_fil_fileds)):\n",
    "#     for v in range(1, num_visits*num_filters):\n",
    "#         m2.add_constraint(\n",
    "#             tc[i][v] - tc[i][v-1] >= (cadence_days + delta) * (x[i][v] + x[i][v-1] - 1),\n",
    "#             ctname=f\"cadence_constraint_field_{i}_visits_{v}\"\n",
    "#         )\n",
    "\n",
    "# for v in range(num_visits * num_filters):\n",
    "#     for i in range(len(selected_fil_fileds)):\n",
    "#         for j in range(i):\n",
    "#             # Ensure i finishes before j starts OR j finishes before i starts\n",
    "#             m2.add_constraint(\n",
    "#                 tc[i][v] + delta * x[i][v] + slew_time_day[i][j] <= tc[j][v] + M * (2 - x[i][v] - x[j][v]),\n",
    "#                 ctname=f\"non_overlapping_field_{i}_{j}_visit_{v}\"\n",
    "#             )\n",
    "#             m2.add_constraint(\n",
    "#                 tc[j][v] + delta * x[j][v] + slew_time_day[i][j] <= tc[i][v] + M * (2 - x[i][v] - x[j][v]),\n",
    "#                 ctname=f\"non_overlapping_field_{j}_{i}_visit_{v}\"\n",
    "#             )\n",
    "\n",
    "\n",
    "# m2.add_constraint(\n",
    "#     m2.sum(x[i][v] for v in range(num_visits*num_filters)) <= 3,\n",
    "#     ctname=f\"max_obs_field_{i}\"\n",
    "# )\n",
    "# # **4. Ensure Observations Stay Within Availability Windows**\n",
    "# for i, row in enumerate(selected_fil_fileds):\n",
    "#     for v in range(num_visits*num_filters):\n",
    "#         m2.add_constraint(\n",
    "#             tc[i][v] >= (row['start_time'] - start_time).to_value(u.day) * x[i][v],\n",
    "#             ctname=f\"start_time_restrict_field_{i}_visit_{v}\"\n",
    "#         )\n",
    "#         m2.add_constraint(\n",
    "#             tc[i][v] <= (row['end_time'] - start_time).to_value(u.day) * x[i][v],\n",
    "#             ctname=f\"end_time_restrict_field_{i}_visit_{v}\"\n",
    "#         )\n",
    "\n",
    "# # **5. Maximize Probability-Weighted Observations**\n",
    "# probabilities = np.array([row['probability'] for row in selected_fil_fileds])\n",
    "# m2.maximize(\n",
    "#     m2.sum(probabilities[i] * x[i][v]\n",
    "#            for i in range(len(selected_fil_fileds))\n",
    "#            for v in range(num_visits*num_filters))\n",
    "# )\n",
    "\n",
    "# # **6. Solver Parameters**\n",
    "# m2.parameters.mip.tolerances.mipgap = 0.01  # 1% optimality gap\n",
    "# m2.parameters.emphasis.mip = 2  # Focus on optimality over feasibility\n",
    "\n",
    "# # **7. Solve the Model**\n",
    "# solution = m2.solve(log_output=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## finding coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for var in field_vars:\n",
    "#     print(solution.get_value(var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Instead of filtering out fields, add an \"availability factor\" to each field\n",
    "# # Compute availability\n",
    "# availability = [\n",
    "#     (row['end_time'] - row['start_time']).to_value(u.day) / (end_time - start_time).to_value(u.day)\n",
    "#     for row in selected_fields\n",
    "# ]\n",
    "\n",
    "# # Add 'availability' to selected_fields\n",
    "# selected_fields['availability'] = availability\n",
    "\n",
    "# # Create selected_fil_fileds with all required columns\n",
    "# selected_fil_fileds = QTable(rows=selected_fields, names=selected_fields.colnames)\n",
    "\n",
    "# # Verify column names\n",
    "# print(\"Columns in selected_fil_fileds:\", selected_fil_fileds.colnames)\n",
    "\n",
    "# # Convert availability to a NumPy array for safe indexing\n",
    "# availabilities = np.array(selected_fil_fileds['availability'])\n",
    "\n",
    "# # Apply constraints using the availability array\n",
    "# for i in range(len(selected_fil_fileds)):\n",
    "#     min_obs = max(1, int(np.ceil(3 * availabilities[i])))\n",
    "#     m2.add_constraint(\n",
    "#         m2.sum(x[i][v] for v in range(num_visits*num_filters)) >= min_obs,\n",
    "#         ctname=f\"min_obs_field_{i}\"\n",
    "#     )\n",
    "\n",
    "\n",
    "# m2 = Model(\"Telescope Scheduling\")\n",
    "# footprints_selected = np.moveaxis(get_footprint(selected_fil_fileds['coord']).cartesian.xyz.value, 0, -1)\n",
    "# footprints_healpix_selected = [\n",
    "#     np.unique(np.concatenate([hp.query_polygon(hpx.nside, v) for v in footprint]))\n",
    "#     for footprint in tqdm(footprints_selected)]\n",
    "\n",
    "# # Compute probabilities for each field\n",
    "# probabilities = []\n",
    "# for field_index in range(len(footprints_healpix_selected)):\n",
    "#     probability_field = np.sum(prob[footprints_healpix_selected[field_index]])\n",
    "#     probabilities.append(probability_field)\n",
    "\n",
    "# # Ensure 'probability' column is properly assigned to selected_fields\n",
    "# selected_fields['probability'] = probabilities\n",
    "\n",
    "# # Create QTable with probabilities included\n",
    "# selected_fil_fileds = QTable(rows=selected_fields, names=selected_fields.colnames)\n",
    "\n",
    "# # Convert probabilities to NumPy array before using in optimization\n",
    "# probabilities = np.array(selected_fil_fileds['probability'])\n",
    "\n",
    "\n",
    "\n",
    "# # selected_fields['probabilities'] = probabilities\n",
    "# # Define observation duration and total observation window\n",
    "# delta = exposure_time.to_value(u.day)  # Observation duration per field\n",
    "# M = (selected_fil_fileds['end_time'].max() - selected_fil_fileds['start_time'].min()).to_value(u.day).item()\n",
    "\n",
    "# # Decision variables: Binary variables for each field and visit\n",
    "# x = [[m2.binary_var(name=f\"x_{i}_visit_{v}\") \n",
    "#       for v in range(num_visits*num_filters)] \n",
    "#       for i in range(len(selected_fil_fileds))]\n",
    "\n",
    "# # Continuous variables for start time of each visit\n",
    "# tc = [[m2.continuous_var(\n",
    "#     lb=(row['start_time'] - start_time).to_value(u.day),\n",
    "#     ub=(row['end_time'] - start_time - exposure_time).to_value(u.day),\n",
    "#     name=f\"start_time_field_{i}_visit_{v}\")\n",
    "#     for v in range(num_visits*num_filters)] \n",
    "#     for i, row in enumerate(selected_fil_fileds)]\n",
    "\n",
    "# # Variables for enforcing non-overlapping observations\n",
    "# visit_transition_times = [m2.continuous_var(\n",
    "#     lb=0, ub=M, name=f\"visit_transition_{v}\")\n",
    "#     for v in range(num_visits*num_filters - 1)]\n",
    "\n",
    "# # **1. Enforce Minimum Observations Proportional to Availability**\n",
    "# for i, row in enumerate(selected_fil_fileds):\n",
    "#     # min_obs = max(1, round(3 * row['availability']))  # Ensure at least 1 observation\n",
    "#     min_obs = max(1, int(np.ceil(3 * row['availability'])))  # Use ceil instead of round\n",
    "\n",
    "#     m2.add_constraint(\n",
    "#         m2.sum(x[i][v] for v in range(num_visits*num_filters)) >= min_obs,\n",
    "#         ctname=f\"min_obs_field_{i}\"\n",
    "#     )\n",
    "\n",
    "# # **2. Enforce Minimum Time Gap Between Observations (30 min)**\n",
    "# cadence_days = (30 * u.minute).to_value(u.day)  # 30 minutes in days\n",
    "\n",
    "# for i in range(len(selected_fil_fileds)):\n",
    "#     for v in range(1, num_visits*num_filters):\n",
    "#         m2.add_constraint(\n",
    "#             tc[i][v] - tc[i][v-1] >= (cadence_days + delta) * (x[i][v] + x[i][v-1] - 1),\n",
    "#             ctname=f\"cadence_constraint_field_{i}_visits_{v}\"\n",
    "#         )\n",
    "\n",
    "# for v in range(num_visits * num_filters):\n",
    "#     for i in range(len(selected_fil_fileds)):\n",
    "#         for j in range(i):\n",
    "#             # Ensure i finishes before j starts OR j finishes before i starts\n",
    "#             m2.add_constraint(\n",
    "#                 tc[i][v] + delta * x[i][v] + slew_time_day[i][j] <= tc[j][v] + M * (2 - x[i][v] - x[j][v]),\n",
    "#                 ctname=f\"non_overlapping_field_{i}_{j}_visit_{v}\"\n",
    "#             )\n",
    "#             m2.add_constraint(\n",
    "#                 tc[j][v] + delta * x[j][v] + slew_time_day[i][j] <= tc[i][v] + M * (2 - x[i][v] - x[j][v]),\n",
    "#                 ctname=f\"non_overlapping_field_{j}_{i}_visit_{v}\"\n",
    "#             )\n",
    "\n",
    "\n",
    "# m2.add_constraint(\n",
    "#     m2.sum(x[i][v] for v in range(num_visits*num_filters)) <= 3,\n",
    "#     ctname=f\"max_obs_field_{i}\"\n",
    "# )\n",
    "# # **4. Ensure Observations Stay Within Availability Windows**\n",
    "# for i, row in enumerate(selected_fil_fileds):\n",
    "#     for v in range(num_visits*num_filters):\n",
    "#         m2.add_constraint(\n",
    "#             tc[i][v] >= (row['start_time'] - start_time).to_value(u.day) * x[i][v],\n",
    "#             ctname=f\"start_time_restrict_field_{i}_visit_{v}\"\n",
    "#         )\n",
    "#         m2.add_constraint(\n",
    "#             tc[i][v] <= (row['end_time'] - start_time).to_value(u.day) * x[i][v],\n",
    "#             ctname=f\"end_time_restrict_field_{i}_visit_{v}\"\n",
    "#         )\n",
    "\n",
    "# # **5. Maximize Probability-Weighted Observations**\n",
    "# probabilities = np.array([row['probability'] for row in selected_fil_fileds])\n",
    "# m2.maximize(\n",
    "#     m2.sum(probabilities[i] * x[i][v]\n",
    "#            for i in range(len(selected_fil_fileds))\n",
    "#            for v in range(num_visits*num_filters))\n",
    "# )\n",
    "\n",
    "# # **6. Solver Parameters**\n",
    "# m2.parameters.mip.tolerances.mipgap = 0.01  # 1% optimality gap\n",
    "# m2.parameters.emphasis.mip = 2  # Focus on optimality over feasibility\n",
    "\n",
    "# # **7. Solve the Model**\n",
    "# solution = m2.solve(log_output=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First model (m1) remains the same as it correctly selects fields covering LIGO localization\n",
    "\n",
    "# Modify the availability calculation to be more granular\n",
    "availability = [\n",
    "    (row['end_time'] - row['start_time']).to_value(u.day) / (end_time - start_time).to_value(u.day)\n",
    "    for row in selected_fields\n",
    "]\n",
    "# Instead of filtering out fields, add an \"availability factor\" to each field\n",
    "\n",
    "# Add 'availability' to selected_fields\n",
    "selected_fields['availability'] = availability\n",
    "\n",
    "# Create selected_fil_fileds with all required columns\n",
    "selected_fil_fileds = QTable(rows=selected_fields, names=selected_fields.colnames)\n",
    "\n",
    "# Verify column names\n",
    "print(\"Columns in selected_fil_fileds:\", selected_fil_fileds.colnames)\n",
    "\n",
    "# Convert availability to a NumPy array for safe indexing\n",
    "availabilities = np.array(selected_fil_fileds['availability'])\n",
    "\n",
    "# Apply constraints using the availability array\n",
    "\n",
    "\n",
    "\n",
    "footprints_selected = np.moveaxis(get_footprint(selected_fil_fileds['coord']).cartesian.xyz.value, 0, -1)\n",
    "footprints_healpix_selected = [\n",
    "    np.unique(np.concatenate([hp.query_polygon(hpx.nside, v) for v in footprint]))\n",
    "    for footprint in tqdm(footprints_selected)]\n",
    "\n",
    "# Compute probabilities for each field\n",
    "probabilities = []\n",
    "for field_index in range(len(footprints_healpix_selected)):\n",
    "    probability_field = np.sum(prob[footprints_healpix_selected[field_index]])\n",
    "    probabilities.append(probability_field)\n",
    "\n",
    "# Ensure 'probability' column is properly assigned to selected_fields\n",
    "selected_fields['probability'] = probabilities\n",
    "\n",
    "# Create QTable with probabilities included\n",
    "selected_fil_fileds = QTable(rows=selected_fields, names=selected_fields.colnames)\n",
    "\n",
    "# Convert probabilities to NumPy array before using in optimization\n",
    "probabilities = np.array(selected_fil_fileds['probability'])\n",
    "# Create the second optimization model\n",
    "m2 = Model(\"Flexible Telescope Scheduling\")\n",
    "\n",
    "# Constants\n",
    "delta = exposure_time.to_value(u.day)\n",
    "M = (observable_fields['end_time'].max() - observable_fields['start_time'].min()).to_value(u.day).item()\n",
    "cadence_days = (30 * u.minute).to_value(u.day)\n",
    "\n",
    "# Decision variables for all fields, not just fully available ones\n",
    "x = [[m2.binary_var(name=f\"x_{i}_visit_{v}\") \n",
    "      for v in range(num_visits*num_filters)] \n",
    "      for i in range(len(selected_fields))]\n",
    "\n",
    "# Continuous variables for observation start times\n",
    "tc = [[m2.continuous_var(\n",
    "    lb=(row['start_time'] - start_time).to_value(u.day),\n",
    "    ub=(row['end_time'] - start_time - exposure_time).to_value(u.day),\n",
    "    name=f\"start_time_field_{i}_visit_{v}\")\n",
    "    for v in range(num_visits*num_filters)] \n",
    "    for i, row in enumerate(selected_fields)]\n",
    "\n",
    "# Modified constraints based on availability\n",
    "for i, row in enumerate(selected_fields):\n",
    "    availability_factor = availability[i]\n",
    "    \n",
    "    # Dynamic minimum and maximum observations based on availability\n",
    "    if availability_factor >= 0.8:\n",
    "        min_obs = 1  # Changed from 3 to 1\n",
    "        max_obs = 3\n",
    "    elif availability_factor >= 0.5:\n",
    "        min_obs = 1  # Changed from 2 to 1\n",
    "        max_obs = 2\n",
    "    else:\n",
    "        min_obs = 1\n",
    "        max_obs = 1\n",
    "    \n",
    "    # Add minimum observation constraint\n",
    "    m2.add_constraint(\n",
    "        m2.sum(x[i][v] for v in range(num_visits*num_filters)) >= min_obs,\n",
    "        ctname=f\"min_obs_field_{i}\"\n",
    "    )\n",
    "    \n",
    "    # Add maximum observation constraint\n",
    "    m2.add_constraint(\n",
    "        m2.sum(x[i][v] for v in range(num_visits*num_filters)) <= max_obs,\n",
    "        ctname=f\"max_obs_field_{i}\"\n",
    "    )\n",
    "\n",
    "    # Add time window constraints\n",
    "    valid_time_windows = []\n",
    "    for v in range(num_visits*num_filters):\n",
    "        # Only add time constraints if the field is actually observed\n",
    "        m2.add_constraint(\n",
    "            tc[i][v] >= (row['start_time'] - start_time).to_value(u.day) * x[i][v],\n",
    "            ctname=f\"start_time_restrict_field_{i}_visit_{v}\"\n",
    "        )\n",
    "        m2.add_constraint(\n",
    "            tc[i][v] <= (row['end_time'] - start_time - exposure_time).to_value(u.day) * x[i][v],\n",
    "            ctname=f\"end_time_restrict_field_{i}_visit_{v}\"\n",
    "        )\n",
    "\n",
    "# Maintain minimum time gap between observations (30 min)\n",
    "for i in range(len(selected_fields)):\n",
    "    for v in range(1, num_visits*num_filters):\n",
    "        m2.add_constraint(\n",
    "            tc[i][v] - tc[i][v-1] >= (cadence_days + delta) * (x[i][v] + x[i][v-1] - 1),\n",
    "            ctname=f\"cadence_constraint_field_{i}_visits_{v}\"\n",
    "        )\n",
    "\n",
    "# Non-overlapping observations constraint\n",
    "for v in range(num_visits * num_filters):\n",
    "    for i in range(len(selected_fields)):\n",
    "        for j in range(i):\n",
    "            m2.add_constraint(\n",
    "                tc[i][v] + delta * x[i][v] + slew_time_day[i][j] <= tc[j][v] + M * (2 - x[i][v] - x[j][v]),\n",
    "                ctname=f\"non_overlapping_field_{i}_{j}_visit_{v}\"\n",
    "            )\n",
    "            m2.add_constraint(\n",
    "                tc[j][v] + delta * x[j][v] + slew_time_day[i][j] <= tc[i][v] + M * (2 - x[i][v] - x[j][v]),\n",
    "                ctname=f\"non_overlapping_field_{j}_{i}_visit_{v}\"\n",
    "            )\n",
    "\n",
    "# Modified objective function incorporating availability and probability\n",
    "probabilities = np.array([row['probability'] for row in selected_fields])\n",
    "availability_weights = np.array(availability)\n",
    "\n",
    "m2.maximize(\n",
    "    m2.sum(probabilities[i] * x[i][v]\n",
    "           for i in range(len(selected_fields))\n",
    "           for v in range(num_visits*num_filters))\n",
    ")\n",
    "\n",
    "# Solver parameters for better convergence\n",
    "# m2.parameters.mip.tolerances.mipgap = 0.05  # 5% optimality gap\n",
    "# m2.parameters.timelimit = 600  # 10 minute time limit\n",
    "# m2.parameters.emphasis.mip = 3  # Balance between feasibility and optimality\n",
    "# m2.parameters.mip.strategy.variableselect = 3  # Strong branching\n",
    "\n",
    "# Solve the model\n",
    "solution = m2.solve(log_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule_matrix = np.zeros((len(selected_fields), num_visits*num_filters))\n",
    "for i in range(len(selected_fields)):\n",
    "    for v in range(num_visits*num_filters):\n",
    "        if solution.get_value(x[i][v]) > 0.0000:  # Using 0.5 as threshold for binary variables\n",
    "            schedule_matrix[i,v] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2 = Model(\"Telescope timings\")\n",
    "footprints_selected = np.moveaxis(get_footprint(selected_fields['coord']).cartesian.xyz.value, 0, -1)\n",
    "footprints_healpix_selected = [\n",
    "    np.unique(np.concatenate([hp.query_polygon(hpx.nside, v) for v in footprint]))\n",
    "    for footprint in tqdm(footprints_selected)]\n",
    "\n",
    "probabilities = []\n",
    "\n",
    "for field_index in range(len(footprints_healpix_selected)):\n",
    "    probability_field = np.sum(prob[footprints_healpix_selected[field_index]])\n",
    "    probabilities.append(probability_field)\n",
    "print(\"worked for\",len(probabilities),\"fields\")\n",
    "\n",
    "selected_fields['probabilities'] = probabilities\n",
    "# Calculate available observation windows\n",
    "available_duration = (selected_fields['end_time'] - selected_fields['start_time']).to_value(u.day)\n",
    "min_required_duration = exposure_time.to_value(u.day) * num_visits\n",
    "field_feasibility = available_duration >= min_required_duration\n",
    "\n",
    "# Keep all fields but mark their feasibility\n",
    "selected_fields['is_feasible'] = field_feasibility\n",
    "\n",
    "delta = exposure_time.to_value(u.day)\n",
    "M = (selected_fields['end_time'].max() - selected_fields['start_time'].min()).to_value(u.day).item()\n",
    "\n",
    "# Decision variables\n",
    "x = [[m2.binary_var(name=f\"x_{i}_visit_{v}\") \n",
    "      for v in range(num_visits)] \n",
    "      for i in range(len(selected_fields))]\n",
    "\n",
    "tc = [[m2.continuous_var(\n",
    "    lb=(row['start_time'] - start_time).to_value(u.day),\n",
    "    ub=(row['end_time'] - start_time - exposure_time).to_value(u.day),\n",
    "    name=f\"start_time_field_{i}_visit_{v}\")\n",
    "    for v in range(num_visits)] \n",
    "    for i, row in enumerate(selected_fields)]\n",
    "\n",
    "# Variables to track if a field completes all visits\n",
    "all_visits_completed = [m2.binary_var(name=f\"complete_{i}\") \n",
    "                       for i in range(len(selected_fields))]\n",
    "\n",
    "# Constraint: Fields must be scheduled within their available windows\n",
    "for i in range(len(selected_fields)):\n",
    "    for v in range(num_visits):\n",
    "        m2.add_constraint(\n",
    "            tc[i][v] + delta * x[i][v] <= \n",
    "            (selected_fields['end_time'][i] - start_time).to_value(u.day),\n",
    "            ctname=f\"end_window_{i}_visit_{v}\"\n",
    "        )\n",
    "        m2.add_constraint(\n",
    "            tc[i][v] >= \n",
    "            (selected_fields['start_time'][i] - start_time).to_value(u.day) * x[i][v],\n",
    "            ctname=f\"start_window_{i}_visit_{v}\"\n",
    "        )\n",
    "\n",
    "# Constraint: Minimum time between visits for the same field\n",
    "for i in range(len(selected_fields)):\n",
    "    for v in range(1, num_visits):\n",
    "        m2.add_constraint(\n",
    "            tc[i][v] - tc[i][v-1] >= cadence_days * (x[i][v] + x[i][v-1] - 1),\n",
    "            ctname=f\"min_separation_{i}_visit_{v}\"\n",
    "        )\n",
    "\n",
    "# Non-overlapping constraint between fields within each visit\n",
    "for v in range(num_visits):\n",
    "    for i in range(len(selected_fields)):\n",
    "        for j in range(i):\n",
    "            # Binary variable for ordering within this visit\n",
    "            zij_v = m2.binary_var(name=f\"z_{i}_{j}_visit_{v}\")\n",
    "            \n",
    "            m2.add_constraint(\n",
    "                tc[i][v] + delta * x[i][v] + slew_time_day[i][j] - tc[j][v] <= \n",
    "                M * (1 - zij_v + (2 - x[i][v] - x[j][v])),\n",
    "                ctname=f\"sequence1_{i}_{j}_visit_{v}\"\n",
    "            )\n",
    "            m2.add_constraint(\n",
    "                tc[j][v] + delta * x[j][v] + slew_time_day[i][j] - tc[i][v] <= \n",
    "                M * (zij_v + (2 - x[i][v] - x[j][v])),\n",
    "                ctname=f\"sequence2_{i}_{j}_visit_{v}\"\n",
    "            )\n",
    "\n",
    "# Constraint: Link completion variable to visits\n",
    "for i in range(len(selected_fields)):\n",
    "    visit_sum = m2.sum(x[i][v] for v in range(num_visits))\n",
    "    m2.add_constraint(\n",
    "        visit_sum >= num_visits * all_visits_completed[i],\n",
    "        ctname=f\"completion_link1_{i}\"\n",
    "    )\n",
    "    m2.add_constraint(\n",
    "        visit_sum <= num_visits - 1 + all_visits_completed[i],\n",
    "        ctname=f\"completion_link2_{i}\"\n",
    "    )\n",
    "\n",
    "# Constraint: Each field can only be scheduled if it's feasible\n",
    "for i in range(len(selected_fields)):\n",
    "    if not field_feasibility[i]:\n",
    "        for v in range(num_visits):\n",
    "            m2.add_constraint(x[i][v] == 0, ctname=f\"infeasible_{i}_visit_{v}\")\n",
    "\n",
    "# Linear objective function\n",
    "m2.maximize(\n",
    "    m2.sum(\n",
    "        probabilities[i] * (\n",
    "            m2.sum(x[i][v] for v in range(num_visits)) +  # Base reward for each visit\n",
    "            0.2 * all_visits_completed[i]  # Bonus for completing all visits\n",
    "        )\n",
    "        for i in range(len(selected_fields))\n",
    "    )\n",
    ")\n",
    "\n",
    "# Solver parameters\n",
    "m2.parameters.mip.tolerances.mipgap = 0.05\n",
    "m2.parameters.timelimit = 300\n",
    "m2.parameters.emphasis.mip = 3\n",
    "m2.parameters.mip.strategy.variableselect = 4\n",
    "m2.parameters.mip.pool.intensity = 2\n",
    "\n",
    "# Solve the model\n",
    "solution = m2.solve(log_output=True)\n",
    "\n",
    "# Process results\n",
    "if solution:\n",
    "    scheduled_fields = []\n",
    "    visit_schedules = []\n",
    "    for i in range(len(selected_fields)):\n",
    "        field_visits = []\n",
    "        for v in range(num_visits):\n",
    "            if solution.get_value(x[i][v]) > 0.5:\n",
    "                field_visits.append({\n",
    "                    'visit': v,\n",
    "                    'time': solution.get_value(tc[i][v])\n",
    "                })\n",
    "        if field_visits:\n",
    "            scheduled_fields.append(i)\n",
    "            visit_schedules.append(field_visits)\n",
    "            \n",
    "    print(f\"Successfully scheduled {len(scheduled_fields)} fields\")\n",
    "    print(f\"Total objective value: {solution.objective_value:.4f}\")\n",
    "else:\n",
    "    print(\"No solution found within the time limit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= np.mean(slew_times)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "#off-center case\n",
    "# ax = plt.axes(projection='astro mollweide', center='0h 60d')\n",
    "ax = plt.axes(projection='astro mollweide', center='0h 0d')\n",
    "\n",
    "for row in selected_fields:\n",
    "    coords = SkyCoord(\n",
    "        [ew_total, -ew_total, -ew_total, ew_total],\n",
    "        [ns_total, ns_total, -ns_total, -ns_total],\n",
    "        frame=row['coord'].skyoffset_frame()\n",
    "    ).icrs\n",
    "    ax.add_patch(plt.Polygon(\n",
    "        np.column_stack((coords.ra.deg, coords.dec.deg)),\n",
    "        alpha=0.5,\n",
    "        facecolor='lightgray',\n",
    "        edgecolor='black',\n",
    "        transform=ax.get_transform('world')\n",
    "    ))\n",
    "# plot_filename = os.path.basename(skymap_file)\n",
    "plot_filename = 'S240910ci'\n",
    "ax.grid()\n",
    "ax.imshow_hpx(prob, cmap='cylon')\n",
    "plt.text(0.05, 0.95, f'Total Probability Covered: {total_prob_covered:.2f}', transform=ax.transAxes,\n",
    "        fontsize=12, verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy import units as u\n",
    "\n",
    "exp_time_list = [60, 120, 180, 240]\n",
    "for i in range(len(exp_time_list)):\n",
    "    exposure_time = exp_time_list[i] * u.second\n",
    "    print(exposure_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time.jd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = exposure_time.to_value(u.day)\n",
    "\n",
    "limit_duration = ((end_time-start_time).value*2/3) \n",
    "filtered_rows = [\n",
    "    row for row in selected_fields\n",
    "    if (row['end_time'] - row['start_time']).to_value(u.day) > limit_duration\n",
    "]\n",
    "\n",
    "# Create a new QTable with the filtered rows\n",
    "selected_fil_fileds = QTable(rows=filtered_rows, names=selected_fields.colnames)\n",
    "\n",
    "selected_fil_fileds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_fil_fileds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Verify time windows for each field\n",
    "# for i, row in enumerate(selected_fields):\n",
    "#     print(f\"Field {i}:\")\n",
    "#     print(f\"Start time: {row['start_time']}\")\n",
    "#     print(f\"End time: {row['end_time']}\")\n",
    "#     print(f\"Window duration: {row['end_time'] - row['start_time']}\")\n",
    "#     delta = exposure_time.to_value(u.day)\n",
    "\n",
    "#     if (row['end_time'] - row['start_time']).to_value(u.day) < (num_visits * num_filters * delta):\n",
    "#         print(f\"Warning: Time window might be too short for field {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2 = Model(\"Telescope timings\")\n",
    "\n",
    "observer_location = EarthLocation.of_site('Palomar')\n",
    "\n",
    "footprints_selected = np.moveaxis(get_footprint(selected_fil_fileds['coord']).cartesian.xyz.value, 0, -1)\n",
    "footprints_healpix_selected = [\n",
    "    np.unique(np.concatenate([hp.query_polygon(hpx.nside, v) for v in footprint]))\n",
    "    for footprint in tqdm(footprints_selected)]\n",
    "\n",
    "probabilities = []\n",
    "\n",
    "for field_index in range(len(footprints_healpix_selected)):\n",
    "    probability_field = np.sum(prob[footprints_healpix_selected[field_index]])\n",
    "    probabilities.append(probability_field)\n",
    "print(\"worked for\",len(probabilities),\"fields\")\n",
    "\n",
    "selected_fil_fileds['probabilities'] = probabilities\n",
    "\n",
    "delta = exposure_time.to_value(u.day)\n",
    "M = (selected_fil_fileds['end_time'].max() - selected_fil_fileds['start_time'].min()).to_value(u.day).item()\n",
    "\n",
    "x = [[m2.binary_var(name=f\"x_{i}_visit_{v}\") \n",
    "      for v in range(num_visits*num_filters)] \n",
    "      for i in range(len(selected_fil_fileds))]\n",
    "\n",
    "tc = [[m2.continuous_var(\n",
    "    lb=(row['start_time'] - start_time).to_value(u.day),\n",
    "    ub=(row['end_time'] - start_time - exposure_time).to_value(u.day),\n",
    "    name=f\"start_time_field_{i}_visit_{v}\")\n",
    "    for v in range(num_visits*num_filters)] \n",
    "    for i, row in enumerate(selected_fil_fileds)]\n",
    "\n",
    "visit_transition_times = [m2.continuous_var(\n",
    "    lb=0,ub=M,name=f\"visit_transition_{v}\")\n",
    "                          for v in range(num_visits*num_filters-1)]  \n",
    "\n",
    "# Isolating visits\n",
    "for v in range(1, num_visits*num_filters):\n",
    "    for i in range(len(selected_fil_fileds)):\n",
    "        m2.add_constraint(tc[i][v-1] + delta * x[i][v-1] <= visit_transition_times[v-1],\n",
    "            ctname=f\"visit_end_{i}_visit_{v-1}\")\n",
    "        m2.add_constraint(tc[i][v] >= visit_transition_times[v-1],\n",
    "            ctname=f\"visit_start_{i}_visit_{v}\")\n",
    "\n",
    "\n",
    "# Cadence constraints\n",
    "for i in range(len(selected_fil_fileds)):\n",
    "    for v in range(1, num_visits*num_filters):\n",
    "        m2.add_constraint(tc[i][v] - tc[i][v-1] >= (cadence_days+delta) * (x[i][v] + x[i][v-1] - 1),\n",
    "            ctname=f\"cadence_constraint_field_{i}_visits_{v}\")\n",
    "\n",
    "#non-overlapping\n",
    "for v in range(num_visits*num_filters):\n",
    "    for i in range(len(selected_fil_fileds)):\n",
    "        for j in range(i):\n",
    "            m2.add_constraint(tc[i][v] + delta * x[i][v] + slew_time_day[i][j] - tc[j][v] <= M * (2 - x[i][v] - x[j][v]),\n",
    "                              ctname=f\"non_overlapping_cross_fields_{i}_{j}_visits_{v}\")\n",
    "            m2.add_constraint(tc[j][v] + delta * x[j][v] + slew_time_day[i][j] - tc[i][v] <= M * (-1 + x[i][v] + x[j][v]),\n",
    "                ctname=f\"non_overlapping_cross_fields_{j}_{i}_visits_{v}\")\n",
    "\n",
    "# Initialize the objective\n",
    "m2.maximize(\n",
    "    m2.sum(probabilities[i] * x[i][v]\n",
    "           for i in range(len(selected_fil_fileds))\n",
    "           for v in range(num_visits*num_filters))\n",
    ")\n",
    "\n",
    "# m2.parameters.timelimit = 60\n",
    "m2.parameters.mip.tolerances.mipgap = 0.01  # 1% optimality gap\n",
    "m2.parameters.emphasis.mip = 2  # Emphasize optimality over feasibility\n",
    "solution = m2.solve(log_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in range(num_visits * num_filters):\n",
    "    visit_fields = [i for i in range(len(selected_fil_fileds)) if solution.get_value(x[i][v]) == 1]\n",
    "    print(visit_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution.objective_value/(num_visits * num_filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scheduled_fields_by_visit = []\n",
    "for v in range(num_visits * num_filters):\n",
    "    visit_fields = [i for i in range(len(selected_fil_fileds)) if solution.get_value(x[i][v]) == 1]\n",
    "    scheduled_fields_by_visit.append(visit_fields)\n",
    "\n",
    "scheduled_fields = selected_fil_fileds.copy()\n",
    "\n",
    "scheduled_tc = []\n",
    "for v in range(num_visits * num_filters):\n",
    "    visit_times = []\n",
    "    for i in range(len(selected_fil_fileds)):\n",
    "        if i in scheduled_fields_by_visit[v]:\n",
    "            visit_times.append(solution.get_value(tc[i][v]))\n",
    "        else:\n",
    "            visit_times.append(np.nan) \n",
    "    scheduled_tc.append(visit_times)\n",
    "\n",
    "scheduled_tc = np.array(scheduled_tc).T  \n",
    "\n",
    "for i in range(num_visits * num_filters):\n",
    "    scheduled_fields[f\"Scheduled_start_filt_times_{i}\"] = scheduled_tc[:, i]\n",
    "\n",
    "for v in range(num_visits * num_filters):\n",
    "    scheduled_fields[f\"Selected_in_visit_{v}\"] = [1 if i in scheduled_fields_by_visit[v] else 0 \n",
    "                                                 for i in range(len(scheduled_fields))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduled_tc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_visits = num_visits * num_filters  \n",
    "\n",
    "fig, axes = plt.subplots(n_visits, 1, figsize=(8, 3 * n_visits), sharex=True)\n",
    "\n",
    "for i in range(n_visits):\n",
    "    start_col = f'Scheduled_start_filt_times_{i}'\n",
    "    end_col = f'Scheduled_end_filt_times_{i}'\n",
    "    \n",
    "    # Filter valid rows\n",
    "    valid_rows = ~np.isnan(scheduled_tc).any(axis=1)\n",
    "    valid_scheduled_tc = scheduled_tc[valid_rows]\n",
    "    valid_scheduled_fields = scheduled_fields[valid_rows]\n",
    "    \n",
    "    if len(valid_scheduled_fields) == 0:\n",
    "        print(f\"No entries found for Visit {i + 1}. Skipping plot.\")\n",
    "        continue  # Skip this visit\n",
    "    \n",
    "    # Convert start times to ISO format and compute end times\n",
    "    valid_scheduled_fields[start_col] = Time(valid_scheduled_fields[start_col], format='mjd')\n",
    "    valid_scheduled_fields[start_col].format = 'iso'\n",
    "    valid_scheduled_fields[end_col] = valid_scheduled_fields[start_col] + exposure_time_day\n",
    "    \n",
    "    # Sort fields by end time\n",
    "    valid_scheduled_fields.sort(end_col)\n",
    "    \n",
    "    # Get the start and end times for plotting\n",
    "    first_start_time = valid_scheduled_fields[start_col].mjd[0]\n",
    "    last_end_time = valid_scheduled_fields[end_col].mjd[-1]\n",
    "    \n",
    "    ax = axes[i]\n",
    "    ax.hlines(\n",
    "        np.arange(len(valid_scheduled_fields)),\n",
    "        valid_scheduled_fields[start_col].mjd,\n",
    "        valid_scheduled_fields[end_col].mjd,\n",
    "        colors='blue',\n",
    "        linewidth=2\n",
    "    )\n",
    "    # Plot small vertical lines at start and end times of each interval\n",
    "    for j in range(len(valid_scheduled_fields)):\n",
    "        ax.vlines(\n",
    "            valid_scheduled_fields[start_col][j].mjd,\n",
    "            ymin=j - 0.2,\n",
    "            ymax=j + 0.2,\n",
    "            color='black',\n",
    "            linewidth=0.5,\n",
    "            linestyle='-'\n",
    "        )\n",
    "        ax.vlines(\n",
    "            valid_scheduled_fields[end_col][j].mjd,\n",
    "            ymin=j - 0.2,\n",
    "            ymax=j + 0.2,\n",
    "            color='black',\n",
    "            linewidth=0.5,\n",
    "            linestyle='-'\n",
    "        )\n",
    "    \n",
    "    # Highlight first start and last end times\n",
    "    if i == 0:  # Add legend only for the first subplot\n",
    "        ax.axvline(first_start_time, color='red', linestyle='--', linewidth=1.5, label='Start of First Field')\n",
    "        ax.axvline(last_end_time, color='green', linestyle='--', linewidth=1.5, label='End of Last Field')\n",
    "        ax.legend(loc='upper right')\n",
    "    else:\n",
    "        ax.axvline(first_start_time, color='red', linestyle='--', linewidth=1.5)\n",
    "        ax.axvline(last_end_time, color='green', linestyle='--', linewidth=1.5)\n",
    "    \n",
    "    # Add labels and title\n",
    "    ax.set_yticks(np.arange(len(valid_scheduled_fields)))\n",
    "    ax.set_yticklabels(valid_scheduled_fields['field_id'].astype(str))\n",
    "    ax.set_ylabel('Field ID')\n",
    "    ax.set_title(f'Observation Schedule for Visit {i + 1}')\n",
    "    \n",
    "axes[-1].set_xlabel('Observation time (MJD)')\n",
    "\n",
    "plt.tight_layout()\n",
    "# save_path = '/u/ywagh/scheduler_results/plots_manuscript'\n",
    "# os.makedirs(save_path, exist_ok=True)  # Ensure directory exists\n",
    "# full_path = os.path.join(save_path, f'schedule_revisit_.png')\n",
    "# plt.savefig(full_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2 = Model(\"Telescope timings\")\n",
    "\n",
    "observer_location = EarthLocation.of_site('Palomar')\n",
    "\n",
    "footprints_selected = np.moveaxis(get_footprint(selected_fields['coord']).cartesian.xyz.value, 0, -1)\n",
    "footprints_healpix_selected = [\n",
    "    np.unique(np.concatenate([hp.query_polygon(hpx.nside, v) for v in footprint]))\n",
    "    for footprint in tqdm(footprints_selected)]\n",
    "\n",
    "probabilities = []\n",
    "\n",
    "for field_index in range(len(footprints_healpix_selected)):\n",
    "    probability_field = np.sum(prob[footprints_healpix_selected[field_index]])\n",
    "    probabilities.append(probability_field)\n",
    "print(\"worked for\",len(probabilities),\"fields\")\n",
    "\n",
    "selected_fields['probabilities'] = probabilities\n",
    "\n",
    "delta = exposure_time.to_value(u.day)\n",
    "M = (selected_fields['end_time'].max() - selected_fields['start_time'].min()).to_value(u.day).item()\n",
    "\n",
    "x = [[m2.binary_var(name=f\"x_{i}_visit_{v}\") \n",
    "      for v in range(num_visits*num_filters)] \n",
    "      for i in range(len(selected_fields))]\n",
    "\n",
    "tc = [[m2.continuous_var(\n",
    "    lb=(row['start_time'] - start_time).to_value(u.day),\n",
    "    ub=(row['end_time'] - start_time - exposure_time).to_value(u.day),\n",
    "    name=f\"start_time_field_{i}_visit_{v}\")\n",
    "    for v in range(num_visits*num_filters)] \n",
    "    for i, row in enumerate(selected_fields)]\n",
    "\n",
    "# Cadence constraints\n",
    "for i in range(len(selected_fields)):\n",
    "    for v in range(1, num_visits*num_filters):\n",
    "        m2.add_constraint(tc[i][v] - tc[i][v-1] >= cadence_days * (x[i][v] + x[i][v-1] - 1),\n",
    "            ctname=f\"cadence_constraint_field_{i}_visits_{v}\")\n",
    "\n",
    "#non-overlapping\n",
    "for v in range(num_visits*num_filters):\n",
    "    for i in range(len(selected_fields)):\n",
    "        for j in range(i):\n",
    "            m2.add_constraint(tc[i][v] + delta * x[i][v] + slew_time_day[i][j] - tc[j][v] <= M * (2 - x[i][v] - x[j][v]),\n",
    "                              ctname=f\"non_overlapping_cross_fields_{i}_{j}_visits_{v}\")\n",
    "            m2.add_constraint(tc[j][v] + delta * x[j][v] + slew_time_day[i][j] - tc[i][v] <= M * (-1 + x[i][v] + x[j][v]),\n",
    "                ctname=f\"non_overlapping_cross_fields_{j}_{i}_visits_{v}\")\n",
    "            \n",
    "# Create auxiliary variables for visit transition times\n",
    "# visit_transition_times = [m2.continuous_var(\n",
    "#     lb=0,  # or appropriate lower bound based on your problem\n",
    "#     ub=M,  # your big-M value\n",
    "#     name=f\"visit_transition_{v}\"\n",
    "# ) for v in range(num_visits*num_filters-1)]  # one less than total visits\n",
    "\n",
    "# # Add constraints for visit transitions\n",
    "# for v in range(1, num_visits*num_filters):\n",
    "#     # All fields from previous visit must end before transition time\n",
    "#     for i in range(len(selected_fields)):\n",
    "#         m2.add_constraint(\n",
    "#             tc[i][v-1] + delta * x[i][v-1] <= visit_transition_times[v-1],\n",
    "#             ctname=f\"visit_end_{i}_visit_{v-1}\"\n",
    "#         )\n",
    "        \n",
    "#         # All fields in current visit must start after transition time\n",
    "#         m2.add_constraint(\n",
    "#             tc[i][v] >= visit_transition_times[v-1],\n",
    "#             ctname=f\"visit_start_{i}_visit_{v}\"\n",
    "#         )\n",
    "\n",
    "# Isolating visits\n",
    "for v in range(1, num_visits*num_filters):\n",
    "    prev_visit_end = m2.max([tc[i][v-1] + 2 * delta * x[i][v-1] for i in range(len(selected_fields))])\n",
    "    for i in range(len(selected_fields)):\n",
    "        m2.add_constraint(tc[i][v] >= prev_visit_end,\n",
    "            ctname=f\"visit_sequence_field_{i}_visit_{v}\")\n",
    "\n",
    "m2.maximize(m2.sum([probabilities[i] * x[i][v]\n",
    "                    for i in range(len(selected_fields))\n",
    "                    for v in range(num_visits*num_filters)]))\n",
    "\n",
    "m2.parameters.timelimit = 60\n",
    "solution2 = m2.solve(log_output=True)\n",
    "\n",
    "'''\n",
    "\n",
    "# Visit ordering constraints\n",
    "# for v in range(1, num_visits*num_filters):\n",
    "#     for i in range(len(selected_fields)):\n",
    "#         m2.add_constraint(tc[i][v] >= tc[len(selected_fields)-1][v-1] + delta + slew_time_day[][],\n",
    "#                           ctname=f\"visit_ordering_constraint_field_{i}_visit_{v}\")\n",
    "# Modified objective function to sum over fields and visits\n",
    "\n",
    "for i in range(len(selected_fields)):\n",
    "    for v in range(1, num_visits*num_filters):\n",
    "        m2.add_constraint(tc[i][v] - tc[i][v-1] >= cadence_days * (x[i][v] + x[i][v-1] - 1),\n",
    "            ctname=f\"cadence_constraint_field_{i}_visits_{v}\")\n",
    "\n",
    "# For the first visit (v=0), use original constraints\n",
    "for i in range(len(selected_fields)):\n",
    "    for j in range(i):\n",
    "        m2.add_constraint(\n",
    "            tc[i][0] + delta * x[i][0] + slew_time_day[i][j] - tc[j][0] <= M * (2 - x[i][0] - x[j][0]),\n",
    "            ctname=f\"non_overlapping_cross_fields_{i}_{j}_visit_0\"\n",
    "        )\n",
    "        m2.add_constraint(\n",
    "            tc[j][0] + delta * x[j][0] + slew_time_day[i][j] - tc[i][0] <= M * (-1 + x[i][0] + x[j][0]),\n",
    "            ctname=f\"non_overlapping_cross_fields_{j}_{i}_visit_0\"\n",
    "        )\n",
    "\n",
    "# For subsequent visits\n",
    "for v in range(1, num_visits*num_filters):\n",
    "    # Calculate end time of previous visit using all fields\n",
    "    prev_visit_end = m2.max([\n",
    "        tc[k][v-1] + delta * x[k][v-1]  \n",
    "        for k in range(len(selected_fields))\n",
    "    ])\n",
    "    \n",
    "    # For current visit\n",
    "    for i in range(len(selected_fields)):\n",
    "        # Ensure field starts after previous visit ends if it's selected\n",
    "        m2.add_constraint(\n",
    "            tc[i][v] >= prev_visit_end - M * (1 - x[i][v]),\n",
    "            ctname=f\"sequential_start_field_{i}_visit_{v}\"\n",
    "        )\n",
    "        \n",
    "        # Non-overlapping constraints within current visit\n",
    "        for j in range(i):\n",
    "            m2.add_constraint(\n",
    "                tc[i][v] + delta * x[i][v] + slew_time_day[i][j] - tc[j][v] <= M * (2 - x[i][v] - x[j][v]),\n",
    "                ctname=f\"non_overlapping_cross_fields_{i}_{j}_visit_{v}\"\n",
    "            )\n",
    "            m2.add_constraint(\n",
    "                tc[j][v] + delta * x[j][v] + slew_time_day[i][j] - tc[i][v] <= M * (-1 + x[i][v] + x[j][v]),\n",
    "                ctname=f\"non_overlapping_cross_fields_{j}_{i}_visit_{v}\"\n",
    "            )\n",
    "m2.maximize(m2.sum([\n",
    "    probabilities[i] * x[i][v] \n",
    "    for i in range(len(selected_fields))\n",
    "    for v in range(num_visits*num_filters)\n",
    "]))\n",
    "\n",
    "m2.parameters.timelimit = 60\n",
    "solution = m2.solve(log_output=True)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### exctracting solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scheduled_fields_by_visit = []\n",
    "# for v in range(num_visits * num_filters):\n",
    "#     visit_fields = [i for i in range(len(selected_fields)) if solution.get_value(x[i][v]) == 1]\n",
    "#     scheduled_fields_by_visit.append(visit_fields)\n",
    "# # scheduled_fields_by_visit\n",
    "\n",
    "# scheduled_tc = []\n",
    "# for v in range(num_visits * num_filters):\n",
    "#     visit_times = []\n",
    "#     for i in range(len(selected_fields)):\n",
    "#         if i in scheduled_fields_by_visit[v]:\n",
    "#             visit_times.append(solution.get_value(tc[i][v]))\n",
    "#         else:\n",
    "#             visit_times.append(np.nan) \n",
    "#     scheduled_tc.append(visit_times)\n",
    "# scheduled_tc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Get the indices of scheduled fields\n",
    "scheduled_fields_ID = [i for i, v in enumerate(x) if v.solution_value == 1]\n",
    "scheduled_fields = selected_fields[scheduled_fields_ID]\n",
    "# scheduled_fields\n",
    "scheduled_tc = [[solution.get_value(tc[i][v]) for v in range(num_visits * num_filters)] for i in scheduled_fields_ID]\n",
    "scheduled_tc = np.asarray(scheduled_tc)\n",
    "# scheduled_fields\n",
    "for i in range(num_visits*num_filters):\n",
    "    scheduled_fields[f\"Scheduled_start_filt_times_{i}\"] = scheduled_tc[:,i] \n",
    "'''\n",
    "scheduled_fields_by_visit = []\n",
    "for v in range(num_visits * num_filters):\n",
    "    visit_fields = [i for i in range(len(selected_fields)) if solution.get_value(x[i][v]) == 1]\n",
    "    scheduled_fields_by_visit.append(visit_fields)\n",
    "\n",
    "scheduled_fields = selected_fields.copy()\n",
    "\n",
    "scheduled_tc = []\n",
    "for v in range(num_visits * num_filters):\n",
    "    visit_times = []\n",
    "    for i in range(len(selected_fields)):\n",
    "        if i in scheduled_fields_by_visit[v]:\n",
    "            visit_times.append(solution.get_value(tc[i][v]))\n",
    "        else:\n",
    "            visit_times.append(np.nan) \n",
    "    scheduled_tc.append(visit_times)\n",
    "\n",
    "scheduled_tc = np.array(scheduled_tc).T  \n",
    "\n",
    "for i in range(num_visits * num_filters):\n",
    "    scheduled_fields[f\"Scheduled_start_filt_times_{i}\"] = scheduled_tc[:, i]\n",
    "\n",
    "for v in range(num_visits * num_filters):\n",
    "    scheduled_fields[f\"Selected_in_visit_{v}\"] = [1 if i in scheduled_fields_by_visit[v] else 0 \n",
    "                                                 for i in range(len(selected_fields))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduled_tc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### garbage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_visits = num_visits * num_filters  \n",
    "\n",
    "fig, axes = plt.subplots(n_visits, 1, figsize=(8, 3 * n_visits), sharex=True)\n",
    "\n",
    "for i in range(n_visits):\n",
    "    start_col = f'Scheduled_start_filt_times_{i}'\n",
    "    end_col = f'Scheduled_end_filt_times_{i}'\n",
    "    \n",
    "    # Convert start times to MJD and set format\n",
    "    scheduled_fields[start_col] = Time(scheduled_fields[start_col], format='mjd')\n",
    "    scheduled_fields[start_col].format = 'iso'\n",
    "    scheduled_fields[end_col] = scheduled_fields[start_col] + exposure_time_day\n",
    "    \n",
    "    # Sort fields by end time for better visualization\n",
    "    scheduled_fields.sort(end_col)\n",
    "    \n",
    "    # Get the start and end times for the vertical lines\n",
    "    first_start_time = scheduled_fields[start_col].mjd[0]\n",
    "    last_end_time = scheduled_fields[end_col].mjd[-1]\n",
    "    \n",
    "    ax = axes[i]  \n",
    "    # Plot observation time intervals as horizontal lines\n",
    "    ax.hlines(\n",
    "        np.arange(len(scheduled_fields)),\n",
    "        scheduled_fields[start_col].mjd,\n",
    "        scheduled_fields[end_col].mjd,\n",
    "        colors='blue',\n",
    "        linewidth=2\n",
    "    )\n",
    "    # Plot small vertical lines at start and end times of each interval\n",
    "    for j in range(len(scheduled_fields)):\n",
    "        ax.vlines(\n",
    "            scheduled_fields[start_col][j].mjd,\n",
    "            ymin=j - 0.2,\n",
    "            ymax=j + 0.2,\n",
    "            color='black',\n",
    "            linewidth=0.5,\n",
    "            linestyle='-'\n",
    "        )\n",
    "        ax.vlines(\n",
    "            scheduled_fields[end_col][j].mjd,\n",
    "            ymin=j - 0.2,\n",
    "            ymax=j + 0.2,\n",
    "            color='black',\n",
    "            linewidth=0.5,\n",
    "            linestyle='-'\n",
    "        )\n",
    "    \n",
    "    # Plot big vertical lines at the start of the first field and end of the last field\n",
    "    ax.axvline(first_start_time, color='red', linestyle='--', linewidth=1.5, label='Start of First Field')\n",
    "    ax.axvline(last_end_time, color='green', linestyle='--', linewidth=1.5, label='End of Last Field')\n",
    "    \n",
    "    # Add labels and title\n",
    "    ax.set_yticks(np.arange(len(scheduled_fields)))\n",
    "    ax.set_yticklabels(scheduled_fields['field_id'].astype(str))\n",
    "    ax.set_ylabel('Field ID')\n",
    "    ax.set_title(f'Observation Schedule for Visit {i + 1}')\n",
    "    ax.legend(loc='upper right')  # Add legend to distinguish vertical lines\n",
    "    \n",
    "axes[-1].set_xlabel('Observation time (MJD)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduled_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from docplex.mp.model import Model\n",
    "\n",
    "# # Make sure all time values are in days\n",
    "# exposure_time_day = exposure_time.to_value(u.day)\n",
    "# cadence_days = cadence / (24 * 60)  # Convert minutes to days\n",
    "\n",
    "# # Create and solve the model\n",
    "\n",
    "\n",
    "# def create_observation_model(prob, observable_fields, exposure_time, cadence_days, slew_time_day, num_visits):\n",
    "#     m = Model(\"Telescope Observation Schedule\")\n",
    "    \n",
    "#     # Index sets\n",
    "#     n_fields = len(observable_fields)\n",
    "    \n",
    "#     # Decision Variables\n",
    "#     # p[i]: pixel i is inside footprint of selected fields (binary)\n",
    "#     p = m.binary_var_list(len(prob), name='pixel')\n",
    "    \n",
    "#     # r[j]: field j is selected (binary)\n",
    "#     r = m.binary_var_list(n_fields, name='field')\n",
    "    \n",
    "#     # t[j,k]: start time of observation j visit k (continuous)\n",
    "#     t = [[m.continuous_var(\n",
    "#         lb=(row['start_time'] - observable_fields['start_time'].min()).to_value(u.day),\n",
    "#         ub=(row['end_time'] - observable_fields['start_time'].min() - exposure_time).to_value(u.day),\n",
    "#         name=f\"start_time_field_{j}_visit_{k}\")\n",
    "#         for k in range(num_visits)] for j, row in enumerate(observable_fields)]\n",
    "    \n",
    "#     # Containment Constraints\n",
    "#     # A pixel is only counted if it's in a selected field\n",
    "#     for i, fields_containing_pixel in enumerate(footprints_healpix_inverse):\n",
    "#         m.add_constraint(\n",
    "#             p[i] <= m.sum(r[j] for j in fields_containing_pixel),\n",
    "#             ctname=f'containment_{i}'\n",
    "#         )\n",
    "    \n",
    "#     # Cadence Constraints\n",
    "#     # Minimum time between visits of the same field\n",
    "#     for j in range(n_fields):\n",
    "#         for k in range(1, num_visits):\n",
    "#             m.add_constraint(\n",
    "#                 t[j][k] - t[j][k-1] >= cadence_days * r[j],\n",
    "#                 ctname=f'cadence_field_{j}_visit_{k}'\n",
    "#             )\n",
    "    \n",
    "#     # No Overlap Constraints\n",
    "#     # Observations must be separated by exposure + slew time\n",
    "#     for j1 in range(n_fields):\n",
    "#         for j2 in range(j1):\n",
    "#             for k1 in range(num_visits):\n",
    "#                 for k2 in range(num_visits):\n",
    "#                     min_separation = exposure_time_day + slew_time_day[j1][j2]\n",
    "#                     # Either j1,k1 happens after j2,k2 or vice versa\n",
    "#                     m.add_constraint(\n",
    "#                         (t[j1][k1] - t[j2][k2] >= min_separation * (r[j1] + r[j2] - 1)) |\n",
    "#                         (t[j2][k2] - t[j1][k1] >= min_separation * (r[j1] + r[j2] - 1)),\n",
    "#                         ctname=f'no_overlap_{j1}_{k1}_{j2}_{k2}'\n",
    "#                     )\n",
    "    \n",
    "#     # Field of Regard Constraints\n",
    "#     # Start time must be within observable window\n",
    "#     for j, field in enumerate(observable_fields):\n",
    "#         for k in range(num_visits):\n",
    "#             m.add_constraint(\n",
    "#                 t[j][k] >= (field['start_time'] - observable_fields['start_time'].min()).to_value(u.day) * r[j],\n",
    "#                 ctname=f'for_start_{j}_{k}'\n",
    "#             )\n",
    "#             m.add_constraint(\n",
    "#                 t[j][k] <= (field['end_time'] - observable_fields['start_time'].min() - exposure_time).to_value(u.day) * r[j],\n",
    "#                 ctname=f'for_end_{j}_{k}'\n",
    "#             )\n",
    "    \n",
    "#     # Objective: Maximize probability coverage\n",
    "#     objective = m.sum(p[i] * prob[i] for i in range(len(prob)))\n",
    "#     m.maximize(objective)\n",
    "    \n",
    "#     return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = create_observation_model(prob, observable_fields, exposure_time_day, cadence_days, slew_time_day, num_visits)\n",
    "# solution = model.solve(log_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import astroplan\n",
    "from astropy.coordinates import ICRS, SkyCoord, AltAz, get_moon, EarthLocation, get_body\n",
    "from astropy import units as u\n",
    "from astropy.utils.data import download_file\n",
    "from astropy.table import Table, QTable, join\n",
    "from astropy.time import Time, TimeDelta\n",
    "from astropy_healpix import *\n",
    "from ligo.skymap import plot\n",
    "from ligo.skymap.io import read_sky_map\n",
    "import healpy as hp\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import datetime as dt\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from docplex.mp.model import Model\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", \"Wswiglal-redir-stdio\")\n",
    "warnings.simplefilter('ignore', astroplan.TargetNeverUpWarning)\n",
    "warnings.simplefilter('ignore', astroplan.TargetAlwaysUpWarning)\n",
    "\n",
    "# directory_path = \"/u/ywagh/test_skymaps/S240422ed.fits\"\n",
    "# skymap, metadata = read_sky_map(os.path.join(directory_path))\n",
    "\n",
    "directory_path = \"/u/ywagh/test_skymaps/\"\n",
    "filelist = sorted([f for f in os.listdir(directory_path) if f.endswith('.gz')])\n",
    "\n",
    "slew_speed = 2.5 * u.deg / u.s\n",
    "slew_accel = 0.4 * u.deg / u.s**2\n",
    "readout = 8.2 * u.s\n",
    "\n",
    "ns_nchips = 4\n",
    "ew_nchips = 4\n",
    "ns_npix = 6144\n",
    "ew_npix = 6160\n",
    "plate_scale = 1.01 * u.arcsec\n",
    "ns_chip_gap = 0.205 * u.deg\n",
    "ew_chip_gap = 0.140 * u.deg\n",
    "\n",
    "ns_total = ns_nchips * ns_npix * plate_scale + (ns_nchips - 1) * ns_chip_gap\n",
    "ew_total = ew_nchips * ew_npix * plate_scale + (ew_nchips - 1) * ew_chip_gap\n",
    "\n",
    "rcid = np.arange(64)\n",
    "\n",
    "chipid, rc_in_chip_id = np.divmod(rcid, 4)\n",
    "ns_chip_index, ew_chip_index = np.divmod(chipid, ew_nchips)\n",
    "ns_rc_in_chip_index = np.where(rc_in_chip_id <= 1, 1, 0)\n",
    "ew_rc_in_chip_index = np.where((rc_in_chip_id == 0) | (rc_in_chip_id == 3), 0, 1)\n",
    "\n",
    "ew_offsets = ew_chip_gap * (ew_chip_index - (ew_nchips - 1) / 2) + ew_npix * plate_scale * (ew_chip_index - ew_nchips / 2) + 0.5 * ew_rc_in_chip_index * plate_scale * ew_npix\n",
    "ns_offsets = ns_chip_gap * (ns_chip_index - (ns_nchips - 1) / 2) + ns_npix * plate_scale * (ns_chip_index - ns_nchips / 2) + 0.5 * ns_rc_in_chip_index * plate_scale * ns_npix\n",
    "\n",
    "ew_ccd_corners = 0.5 * plate_scale * np.asarray([ew_npix, 0, 0, ew_npix])\n",
    "ns_ccd_corners = 0.5 * plate_scale * np.asarray([ns_npix, ns_npix, 0, 0])\n",
    "\n",
    "ew_vertices = ew_offsets[:, np.newaxis] + ew_ccd_corners[np.newaxis, :]\n",
    "ns_vertices = ns_offsets[:, np.newaxis] + ns_ccd_corners[np.newaxis, :]\n",
    "\n",
    "def get_footprint(center):\n",
    "    return SkyCoord(\n",
    "        ew_vertices, ns_vertices,\n",
    "        frame=center[..., np.newaxis, np.newaxis].skyoffset_frame()\n",
    "    ).icrs\n",
    "\n",
    "url = 'https://github.com/ZwickyTransientFacility/ztf_information/raw/master/field_grid/ZTF_Fields.txt'\n",
    "filename = download_file(url)\n",
    "field_grid = QTable(np.recfromtxt(filename, comments='%', usecols=range(3), names=['field_id', 'ra', 'dec']))\n",
    "field_grid['coord'] = SkyCoord(field_grid.columns.pop('ra') * u.deg, field_grid.columns.pop('dec') * u.deg)\n",
    "field_grid = field_grid[0:881]\n",
    "\n",
    "#******************************************************************************\n",
    "skymap, metadata = read_sky_map(os.path.join(directory_path, filelist[40]))\n",
    "\n",
    "plot_filename = os.path.basename(filelist[40])\n",
    "# plot_filename = 'S240422ed'\n",
    "# ci\n",
    "#******************************************************************************\n",
    "\n",
    "event_time = Time(metadata['gps_time'], format='gps').utc\n",
    "event_time.format = 'iso'\n",
    "\n",
    "event_time = Time(metadata['gps_time'], format='gps').utc\n",
    "event_time.format = 'iso'\n",
    "print('event time:',event_time)\n",
    "observer = astroplan.Observer.at_site('Palomar')\n",
    "night_horizon = -18 * u.deg\n",
    "if observer.is_night(event_time, horizon=night_horizon):\n",
    "    start_time = event_time\n",
    "else:\n",
    "    start_time = observer.sun_set_time(\n",
    "        event_time, horizon=night_horizon, which='next')\n",
    "\n",
    "# Find the latest possible end time of observations: the time of sunrise.\n",
    "end_time = observer.sun_rise_time(\n",
    "    start_time, horizon=night_horizon, which='next')\n",
    "\n",
    "min_airmass = 2.5 * u.dimensionless_unscaled\n",
    "airmass_horizon = (90 * u.deg - np.arccos(1 / min_airmass))\n",
    "targets = field_grid['coord']\n",
    "\n",
    "# Find the time that each field rises and sets above an airmass of 2.5.\n",
    "target_start_time = Time(np.where(\n",
    "    observer.target_is_up(start_time, targets, horizon=airmass_horizon),\n",
    "    start_time,\n",
    "    observer.target_rise_time(start_time, targets, which='next', horizon=airmass_horizon)))\n",
    "target_start_time.format = 'iso'\n",
    "\n",
    "# Find the time that each field sets below the airmass limit. If the target\n",
    "# is always up (i.e., it's circumpolar) or if it sets after surnsise,\n",
    "# then set the end time to sunrise.\n",
    "target_end_time = observer.target_set_time(\n",
    "    target_start_time, targets, which='next', horizon=airmass_horizon)\n",
    "target_end_time[\n",
    "    (target_end_time.mask & ~target_start_time.mask) | (target_end_time > end_time)\n",
    "] = end_time\n",
    "target_end_time.format = 'iso'\n",
    "# Select fields that are observable for long enough for at least one exposure\n",
    "##############################################################################\n",
    "exposure_time = 180 * u.second\n",
    "exposure_time_day = exposure_time.to_value(u.day)\n",
    "\n",
    "num_visits = 2\n",
    "num_filters = 2\n",
    "\n",
    "cadence = 60         #minutes\n",
    "cadence_days = cadence / (60 * 24)\n",
    "##############################################################################\n",
    "field_grid['start_time'] = target_start_time\n",
    "field_grid['end_time'] = target_end_time\n",
    "observable_fields = field_grid[target_end_time - target_start_time >= exposure_time]\n",
    "\n",
    "# print(observable_fields)\n",
    "hpx = HEALPix(nside=256, frame=ICRS())\n",
    "\n",
    "footprint = np.moveaxis(\n",
    "    get_footprint(SkyCoord(0 * u.deg, 0 * u.deg)).cartesian.xyz.value, 0, -1)\n",
    "footprint_healpix = np.unique(np.concatenate(\n",
    "    [hp.query_polygon(hpx.nside, v, nest=(hpx.order == 'nested')) for v in footprint]))\n",
    "\n",
    "'''\n",
    "# computing the footprints of every ZTF field as HEALPix indices. Downsampling skymap to same resolution.\n",
    "'''\n",
    "footprints = np.moveaxis(get_footprint(observable_fields['coord']).cartesian.xyz.value, 0, -1)\n",
    "footprints_healpix = [\n",
    "    np.unique(np.concatenate([hp.query_polygon(hpx.nside, v) for v in footprint]))\n",
    "    for footprint in tqdm(footprints)]\n",
    "\n",
    "prob = hp.ud_grade(skymap, hpx.nside, power=-2)\n",
    "\n",
    "# k = max number of 300s exposures \n",
    "min_start = min(observable_fields['start_time'])\n",
    "max_end =max(observable_fields['end_time'])\n",
    "# min_start.format = 'jd'\n",
    "# max_end.format = 'jd'\n",
    "\n",
    "\n",
    "\n",
    "k = int(np.floor((max_end - min_start)/(2*exposure_time.to(u.day))))\n",
    "k = np.floor(k/(num_visits*num_filters))\n",
    "print(k,\" number of exposures could be taken tonight\")\n",
    "\n",
    "print(\"problem setup completed\")\n",
    "\n",
    "m1 = Model('max coverage problem')\n",
    "\n",
    "field_vars = m1.binary_var_list(len(footprints), name='field')\n",
    "pixel_vars = m1.binary_var_list(hpx.npix, name='pixel')\n",
    "\n",
    "footprints_healpix_inverse = [[] for _ in range(hpx.npix)]\n",
    "\n",
    "for field, pixels in enumerate(footprints_healpix):\n",
    "    for pixel in pixels:\n",
    "        footprints_healpix_inverse[pixel].append(field)\n",
    "\n",
    "for i_pixel, i_fields in enumerate(footprints_healpix_inverse):\n",
    "     m1.add_constraint(m1.sum(field_vars[i] for i in i_fields) >= pixel_vars[i_pixel])\n",
    "\n",
    "m1.add_constraint(m1.sum(field_vars) <= k)\n",
    "m1.maximize(m1.dot(pixel_vars, prob))\n",
    "print(f\"number fo fields observed should be less than {k}\")\n",
    "\n",
    "solution = m1.solve(log_output=True)\n",
    "\n",
    "print(\"optimization completed\")\n",
    "total_prob_covered = solution.objective_value\n",
    "\n",
    "print(\"Total probability covered:\",total_prob_covered)\n",
    "\n",
    "selected_fields_ID = [i for i, v in enumerate(field_vars) if v.solution_value == 1]\n",
    "print(len(selected_fields_ID), \"fields selected\")\n",
    "selected_fields = observable_fields[selected_fields_ID]\n",
    "# print(selected_fields)\n",
    "\n",
    "separation_matrix = selected_fields['coord'][:,np.newaxis].separation(selected_fields['coord'][np.newaxis,:])\n",
    "\n",
    "def slew_time(separation):\n",
    "   return np.where(separation <= (slew_speed**2 / slew_accel),\n",
    "                   np.sqrt(2 * separation / slew_accel),\n",
    "                   (2 * slew_speed / slew_accel) + (separation - slew_speed**2 / slew_accel) / slew_speed)\n",
    "\n",
    "slew_times = slew_time(separation_matrix).value\n",
    "\n",
    "slew_time_value = slew_times*u.second\n",
    "slew_time_day = slew_time_value.to_value(u.day)\n",
    "\n",
    "m2 = Model(\"Telescope timings\")\n",
    "\n",
    "observer_location = EarthLocation.of_site('Palomar')\n",
    "\n",
    "footprints_selected = np.moveaxis(get_footprint(selected_fields['coord']).cartesian.xyz.value, 0, -1)\n",
    "footprints_healpix_selected = [\n",
    "    np.unique(np.concatenate([hp.query_polygon(hpx.nside, v) for v in footprint]))\n",
    "    for footprint in tqdm(footprints_selected)]\n",
    "\n",
    "probabilities = []\n",
    "\n",
    "for field_index in range(len(footprints_healpix_selected)):\n",
    "    probability_field = np.sum(prob[footprints_healpix_selected[field_index]])\n",
    "    probabilities.append(probability_field)\n",
    "print(\"worked for\",len(probabilities),\"fields\")\n",
    "\n",
    "selected_fields['probabilities'] = probabilities\n",
    "\n",
    "delta = exposure_time.to_value(u.day)\n",
    "M = (selected_fields['end_time'].max() - selected_fields['start_time'].min()).to_value(u.day).item()\n",
    "\n",
    "x = [[m2.binary_var(name=f\"x_{i}_visit_{v}\") \n",
    "      for v in range(num_visits*num_filters)] \n",
    "      for i in range(len(selected_fields))]\n",
    "\n",
    "tc = [[m2.continuous_var(\n",
    "    lb=(row['start_time'] - start_time).to_value(u.day),\n",
    "    ub=(row['end_time'] - start_time - exposure_time).to_value(u.day),\n",
    "    name=f\"start_time_field_{i}_visit_{v}\")\n",
    "    for v in range(num_visits*num_filters)] \n",
    "    for i, row in enumerate(selected_fields)]\n",
    "\n",
    "visit_transition_times = [m2.continuous_var(\n",
    "    lb=0,ub=M,name=f\"visit_transition_{v}\")\n",
    "                          for v in range(num_visits*num_filters-1)]  \n",
    "\n",
    "# Isolating visits\n",
    "for v in range(1, num_visits*num_filters):\n",
    "    for i in range(len(selected_fields)):\n",
    "        m2.add_constraint(tc[i][v-1] + delta * x[i][v-1] <= visit_transition_times[v-1],\n",
    "            ctname=f\"visit_end_{i}_visit_{v-1}\")\n",
    "        m2.add_constraint(tc[i][v] >= visit_transition_times[v-1],\n",
    "            ctname=f\"visit_start_{i}_visit_{v}\")\n",
    "\n",
    "# Cadence constraints\n",
    "for i in range(len(selected_fields)):\n",
    "    for v in range(1, num_visits*num_filters):\n",
    "        m2.add_constraint(tc[i][v] - tc[i][v-1] >= (cadence_days+delta) * (x[i][v] + x[i][v-1] - 1),\n",
    "            ctname=f\"cadence_constraint_field_{i}_visits_{v}\")\n",
    "\n",
    "#non-overlapping constraints\n",
    "# for v in range(num_visits * num_filters):\n",
    "#     for i in range(len(selected_fields)):\n",
    "#         for j in range(i):  # Ensure j < i to avoid duplicate constraints\n",
    "#             buffer_time = 0.001  # Small buffer to prevent exact equality issues\n",
    "            \n",
    "#             m2.add_indicator(x[i][v], \n",
    "#                            tc[i][v] + delta + slew_time_day[i][j] + buffer_time <= tc[j][v],\n",
    "#                            name=f\"indicator_constraint_{i}_to_{j}_visit_{v}\")\n",
    "            \n",
    "#             m2.add_indicator(x[j][v], \n",
    "#                            tc[j][v] + delta + slew_time_day[i][j] + buffer_time <= tc[i][v],\n",
    "#                            name=f\"indicator_constraint_{j}_to_{i}_visit_{v}\")\n",
    "\n",
    "\n",
    "#non-overlapping\n",
    "for v in range(num_visits*num_filters):\n",
    "    for i in range(len(selected_fields)):\n",
    "        for j in range(i):\n",
    "            m2.add_constraint(tc[i][v] + delta * x[i][v] + slew_time_day[i][j] - tc[j][v] <= M * (2 - x[i][v] - x[j][v]),\n",
    "                              ctname=f\"non_overlapping_cross_fields_{i}_{j}_visits_{v}\")\n",
    "            m2.add_constraint(tc[j][v] + delta * x[j][v] + slew_time_day[i][j] - tc[i][v] <= M * (-1 + x[i][v] + x[j][v]),\n",
    "                ctname=f\"non_overlapping_cross_fields_{j}_{i}_visits_{v}\")\n",
    "\n",
    "m2.maximize(m2.sum([probabilities[i] * x[i][v]\n",
    "                    for i in range(len(selected_fields))\n",
    "                    for v in range(num_visits*num_filters)]))\n",
    "\n",
    "m2.parameters.timelimit = 60\n",
    "m2.parameters.mip.tolerances.mipgap = 0.01  # 1% optimality gap\n",
    "m2.parameters.emphasis.mip = 2  # Emphasize optimality over feasibility\n",
    "solution = m2.solve(log_output=True)\n",
    "\n",
    "scheduled_fields_by_visit = []\n",
    "for v in range(num_visits * num_filters):\n",
    "    visit_fields = [i for i in range(len(selected_fields)) if solution.get_value(x[i][v]) == 1]\n",
    "    scheduled_fields_by_visit.append(visit_fields)\n",
    "\n",
    "scheduled_fields = selected_fields.copy()\n",
    "\n",
    "scheduled_tc = []\n",
    "for v in range(num_visits * num_filters):\n",
    "    visit_times = []\n",
    "    for i in range(len(selected_fields)):\n",
    "        if i in scheduled_fields_by_visit[v]:\n",
    "            visit_times.append(solution.get_value(tc[i][v]))\n",
    "        else:\n",
    "            visit_times.append(np.nan) \n",
    "    scheduled_tc.append(visit_times)\n",
    "\n",
    "scheduled_tc = np.array(scheduled_tc).T  \n",
    "\n",
    "for i in range(num_visits * num_filters):\n",
    "    scheduled_fields[f\"Scheduled_start_filt_times_{i}\"] = scheduled_tc[:, i]\n",
    "\n",
    "for v in range(num_visits * num_filters):\n",
    "    scheduled_fields[f\"Selected_in_visit_{v}\"] = [1 if i in scheduled_fields_by_visit[v] else 0 \n",
    "                                                 for i in range(len(scheduled_fields))]\n",
    "\n",
    "\n",
    "\n",
    "n_visits = num_visits * num_filters  \n",
    "\n",
    "fig, axes = plt.subplots(n_visits, 1, figsize=(8, 3 * n_visits), sharex=True)\n",
    "\n",
    "for i in range(n_visits):\n",
    "    start_col = f'Scheduled_start_filt_times_{i}'\n",
    "    end_col = f'Scheduled_end_filt_times_{i}'\n",
    "    valid_rows = ~np.isnan(scheduled_tc).any(axis=1)\n",
    "    valid_scheduled_tc = scheduled_tc[valid_rows]\n",
    "    valid_scheduled_fields = scheduled_fields[valid_rows]\n",
    "    valid_field_ids = scheduled_fields['field_id'][valid_rows]\n",
    "\n",
    "\n",
    "    # Also get corresponding field IDs if needed\n",
    "    valid_scheduled_fields[start_col] = Time(valid_scheduled_fields[start_col], format='mjd')\n",
    "    valid_scheduled_fields[start_col].format = 'iso'\n",
    "    valid_scheduled_fields[end_col] = valid_scheduled_fields[start_col] + exposure_time_day\n",
    "    \n",
    "    # Sort fields by end time for better visualization\n",
    "    valid_scheduled_fields.sort(end_col)\n",
    "    \n",
    "    # Get the start and end times for the vertical lines\n",
    "    first_start_time = valid_scheduled_fields[start_col].mjd[0]\n",
    "    last_end_time = valid_scheduled_fields[end_col].mjd[-1]\n",
    "    \n",
    "    ax = axes[i]  \n",
    "    ax.hlines(\n",
    "        np.arange(len(valid_scheduled_fields)),\n",
    "        valid_scheduled_fields[start_col].mjd,\n",
    "        valid_scheduled_fields[end_col].mjd,\n",
    "        colors='blue',\n",
    "        linewidth=2\n",
    "    )\n",
    "    # Plot small vertical lines at start and end times of each interval\n",
    "    for j in range(len(valid_scheduled_fields)):\n",
    "        ax.vlines(\n",
    "            valid_scheduled_fields[start_col][j].mjd,\n",
    "            ymin=j - 0.2,\n",
    "            ymax=j + 0.2,\n",
    "            color='black',\n",
    "            linewidth=0.5,\n",
    "            linestyle='-'\n",
    "        )\n",
    "        ax.vlines(\n",
    "            valid_scheduled_fields[end_col][j].mjd,\n",
    "            ymin=j - 0.2,\n",
    "            ymax=j + 0.2,\n",
    "            color='black',\n",
    "            linewidth=0.5,\n",
    "            linestyle='-'\n",
    "        )\n",
    "    \n",
    "    # Plot big vertical lines at the start of the first field and end of the last field\n",
    "    ax.axvline(first_start_time, color='red', linestyle='--', linewidth=1.5, label='Start of First Field')\n",
    "    ax.axvline(last_end_time, color='green', linestyle='--', linewidth=1.5, label='End of Last Field')\n",
    "    \n",
    "    # Add labels and title\n",
    "    ax.set_yticks(np.arange(len(valid_scheduled_fields)))\n",
    "    ax.set_yticklabels(valid_scheduled_fields['field_id'].astype(str))\n",
    "    ax.set_ylabel('Field ID')\n",
    "    ax.set_title(f'Observation Schedule for Visit {i + 1}')\n",
    "    ax.legend(loc='upper right')  # Add legend to distinguish vertical lines\n",
    "    \n",
    "axes[-1].set_xlabel('Observation time (MJD)')\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.title(f'Total Cumulative Probability per Field:{total_cum_prob}')\n",
    "plt.savefig('revisit_plots.png', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduled_fields_by_visit = []\n",
    "for v in range(num_visits * num_filters):\n",
    "    visit_fields = [i for i in range(len(selected_fields)) if solution.get_value(x[i][v]) == 1]\n",
    "    scheduled_fields_by_visit.append(visit_fields)\n",
    "\n",
    "scheduled_fields = selected_fields.copy()\n",
    "\n",
    "scheduled_tc = []\n",
    "for v in range(num_visits * num_filters):\n",
    "    visit_times = []\n",
    "    for i in range(len(selected_fields)):\n",
    "        if i in scheduled_fields_by_visit[v]:\n",
    "            visit_times.append(solution.get_value(tc[i][v]))\n",
    "        else:\n",
    "            visit_times.append(np.nan) \n",
    "    scheduled_tc.append(visit_times)\n",
    "\n",
    "scheduled_tc = np.array(scheduled_tc).T  \n",
    "\n",
    "for i in range(num_visits * num_filters):\n",
    "    scheduled_fields[f\"Scheduled_start_filt_times_{i}\"] = scheduled_tc[:, i]\n",
    "\n",
    "for v in range(num_visits * num_filters):\n",
    "    scheduled_fields[f\"Selected_in_visit_{v}\"] = [1 if i in scheduled_fields_by_visit[v] else 0 \n",
    "                                                 for i in range(len(selected_fields))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get indices of rows that don't have any NaN values\n",
    "valid_rows = ~np.isnan(scheduled_tc).any(axis=1)\n",
    "# valid_rows\n",
    "# Create new array with only valid rows\n",
    "valid_scheduled_tc = scheduled_tc[valid_rows]\n",
    "valid_scheduled_tc\n",
    "# Also get corresponding field IDs if needed\n",
    "# valid_field_ids = scheduled_fields['field_id'][valid_rows]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dumping yard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sliding time window parameters\n",
    "window_size = 1 * u.hour  # 1-hour windows\n",
    "window_duration = window_size.to_value(u.day)  # Convert to days\n",
    "time_windows = np.arange(\n",
    "    min_start.to_value(u.day), \n",
    "    max_end.to_value(u.day), \n",
    "    window_duration\n",
    ")\n",
    "\n",
    "# Collect results across all time windows\n",
    "scheduled_fields_all_windows = []\n",
    "probabilities_covered = []\n",
    "\n",
    "for window_start in time_windows:\n",
    "    window_end = window_start + window_duration\n",
    "\n",
    "    # Filter fields that can be observed within this time window\n",
    "    window_fields = selected_fields[\n",
    "        (selected_fields['start_time'].to_value(u.day) <= window_end) &\n",
    "        (selected_fields['end_time'].to_value(u.day) >= window_start)\n",
    "    ]\n",
    "    if len(window_fields) == 0:\n",
    "        continue\n",
    "\n",
    "    # Precompute valid field pairs for the window\n",
    "    window_separation_matrix = window_fields['coord'][:, np.newaxis].separation(\n",
    "        window_fields['coord'][np.newaxis, :]\n",
    "    )\n",
    "    window_slew_times = slew_time(window_separation_matrix).to_value(u.day)\n",
    "    valid_pairs = [\n",
    "        (i, j)\n",
    "        for i in range(len(window_fields))\n",
    "        for j in range(i)\n",
    "        if window_slew_times[i, j] + delta <= M\n",
    "    ]\n",
    "\n",
    "    # Create new Model 2 for the time window\n",
    "    m2 = Model(f\"Telescope timings (Window {window_start}-{window_end})\")\n",
    "    \n",
    "    # Decision variables\n",
    "    x = [[m2.binary_var(name=f\"x_{i}_visit_{v}\") \n",
    "          for v in range(num_visits*num_filters)] \n",
    "          for i in range(len(window_fields))]\n",
    "\n",
    "    tc = [[m2.continuous_var(\n",
    "        lb=max(window_fields['start_time'][i].to_value(u.day), window_start),\n",
    "        ub=min(window_fields['end_time'][i].to_value(u.day), window_end - delta),\n",
    "        name=f\"start_time_field_{i}_visit_{v}\")\n",
    "        for v in range(num_visits*num_filters)] \n",
    "        for i in range(len(window_fields))]\n",
    "\n",
    "    visit_transition_times = [m2.continuous_var(\n",
    "        lb=window_start, ub=window_end, name=f\"visit_transition_{v}\")\n",
    "                              for v in range(num_visits*num_filters - 1)]\n",
    "\n",
    "    # Constraints\n",
    "    for v in range(1, num_visits*num_filters):\n",
    "        for i in range(len(window_fields)):\n",
    "            m2.add_constraint(tc[i][v-1] + delta * x[i][v-1] <= visit_transition_times[v-1],\n",
    "                              ctname=f\"visit_end_{i}_visit_{v-1}\")\n",
    "            m2.add_constraint(tc[i][v] >= visit_transition_times[v-1],\n",
    "                              ctname=f\"visit_start_{i}_visit_{v}\")\n",
    "\n",
    "    for i in range(len(window_fields)):\n",
    "        for v in range(1, num_visits*num_filters):\n",
    "            m2.add_constraint(tc[i][v] - tc[i][v-1] >= cadence_days * (x[i][v] + x[i][v-1] - 1),\n",
    "                              ctname=f\"cadence_constraint_field_{i}_visits_{v}\")\n",
    "\n",
    "    # Non-overlapping constraints for valid pairs\n",
    "    for v in range(num_visits*num_filters):\n",
    "        for i, j in valid_pairs:\n",
    "            m2.add_constraint(tc[i][v] + delta * x[i][v] + window_slew_times[i, j] - tc[j][v] <= M * (2 - x[i][v] - x[j][v]),\n",
    "                              ctname=f\"non_overlapping_cross_fields_{i}_{j}_visits_{v}\")\n",
    "            m2.add_constraint(tc[j][v] + delta * x[j][v] + window_slew_times[i, j] - tc[i][v] <= M * (-1 + x[i][v] + x[j][v]),\n",
    "                              ctname=f\"non_overlapping_cross_fields_{j}_{i}_visits_{v}\")\n",
    "\n",
    "    # Objective\n",
    "    m2.maximize(m2.sum([probabilities[i] * x[i][v]\n",
    "                        for i in range(len(window_fields))\n",
    "                        for v in range(num_visits*num_filters)]))\n",
    "\n",
    "    # Solve\n",
    "    m2.parameters.timelimit = 300\n",
    "    m2.parameters.mip.tolerances.mipgap = 0.05\n",
    "    solution = m2.solve(log_output=True)\n",
    "\n",
    "    if solution:\n",
    "        total_prob = solution.objective_value\n",
    "        probabilities_covered.append(total_prob)\n",
    "\n",
    "        # Extract scheduled fields and times\n",
    "        scheduled_fields_by_visit = []\n",
    "        for v in range(num_visits * num_filters):\n",
    "            visit_fields = [i for i in range(len(window_fields)) if solution.get_value(x[i][v]) == 1]\n",
    "            scheduled_fields_by_visit.append(visit_fields)\n",
    "        scheduled_fields_all_windows.append((window_start, window_end, scheduled_fields_by_visit))\n",
    "\n",
    "# Combine results across windows if necessary\n",
    "# (Implement further logic to consolidate results across time windows if needed)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MILP_3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
